{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://paperswithcode.com/datasets?mod=images&page=1'\n",
    "res = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "title = soup.find_all(class_='filter-items')\n",
    "\n",
    "counter = 0\n",
    "title_list = []\n",
    "while True:\n",
    "    try:\n",
    "        text = title[1].contents[counter].get_text(strip=True)\n",
    "        if text != '':\n",
    "            text = re.sub(r'\\d*$', '', text)\n",
    "            title_list.append(text)\n",
    "        counter += 1\n",
    "    except IndexError:\n",
    "        break\n",
    "\n",
    "len(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browser = webdriver.Chrome()\n",
    "\n",
    "# ヘッドレスモード\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "browser = webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "browser.set_window_size('1200', '1000')\n",
    "browser.get('https://paperswithcode.com/')\n",
    "\n",
    "obj = []\n",
    "not_page =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/499]  Semantic Segmentation is a computer vision task in which the goal is to categorize each pixel in an image into a class or object. The goal is to produce a dense pixel-wise segmentation map of an image, where each pixel is assigned to a specific class or object. Some example benchmarks for this task are Cityscapes, PASCAL VOC and ADE20K. Models are usually evaluated with the Mean Intersection-Over-Union (Mean IoU) and Pixel Accuracy metrics.\n",
      "( Image credit: CSAILVision )\n",
      "[1/499]  Object Detection is a computer vision task in which the goal is to detect and locate objects of interest in an image or video. The task involves identifying the position and boundaries of objects in an image, and classifying the objects into different categories.\n",
      "The state-of-the-art methods can be categorized into two main types: one-stage methods and two stage-methods:\n",
      "One-stage methods prioritize inference speed, and example models include YOLO, SSD and RetinaNet.\n",
      "Two-stage methods prioritize detection accuracy, and example models include Faster R-CNN, Mask R-CNN and Cascade R-CNN.\n",
      "The most popular benchmark is the MSCOCO dataset. Models are typically evaluated according to a Mean Average Precision metric.\n",
      "( Image credit: Detectron )\n",
      "[2/499]  Image Classification is a fundamental task that attempts to comprehend an entire image as a whole. The goal is to classify the image by assigning it to a specific label. Typically, Image Classification refers to images in which only one object appears and is analyzed. In contrast, object detection involves both classification and localization tasks, and is used to analyze more realistic cases in which multiple objects may exist in an image.\n",
      "Source: Metamorphic Testing for Object Detection Systems\n",
      "[3/499]  Pose Estimation is a computer vision task where the goal is to detect the position and orientation of a person or an object. Usually, this is done by predicting the location of specific keypoints like hands, head, elbows, etc. in case of Human Pose Estimation.\n",
      "A common benchmark for this task is MPII Human Pose\n",
      "( Image credit: Real-time 2D Multi-Person Pose Estimation on CPU: Lightweight OpenPose )\n",
      "[4/499]  Facial Recognition is the task of making a positive identification of a face in a photo or video image against a pre-existing database of faces. It begins with detection - distinguishing human faces from other objects in the image - and then works on identification of those detected faces.\n",
      "The state of the art tables for this task are contained mainly in the consistent parts of the task : the face verification and face identification tasks.\n",
      "( Image credit: Face Verification )\n",
      "[5/499]  Visual Question Answering (VQA) is a task in computer vision that involves answering questions about an image. The goal of VQA is to teach machines to understand the content of an image and answer questions about it in natural language.\n",
      "Image Source: visualqa.org\n",
      "[6/499]  Image Retrieval is a computer vision task that involves searching for images in a large database that are similar to a given query image. The goal of image retrieval is to enable users to find images that match their interests or needs, based on visual similarity or other criteria.\n",
      "( Image credit: DELF )\n",
      "[7/499]  Depth Estimation is the task of measuring the distance of each pixel relative to the camera. Depth is extracted from either monocular (single) or stereo (multiple views of a scene) images. Traditional methods use multi-view geometry to find the relationship between the images. Newer methods can directly estimate depth by minimizing the regression loss, or by learning to generate a novel view from a sequence. The most popular benchmarks are KITTI and NYUv2. Models are typically evaluated according to a RMS metric.\n",
      "Source: DIODE: A Dense Indoor and Outdoor DEpth Dataset\n",
      "[8/499]  Instance Segmentation is a computer vision task that involves identifying and separating individual objects within an image, including detecting the boundaries of each object and assigning a unique label to each object. The goal of instance segmentation is to produce a pixel-wise segmentation map of the image, where each pixel is assigned to a specific object instance.\n",
      "Image Credit: Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers, CVPR'21\n",
      "[9/499]  Dragon\n",
      "[10/499]  Question Answering is the task of answering questions (typically reading comprehension questions), but abstaining when presented with a question that cannot be answered based on the provided context.\n",
      "Question answering can be segmented into domain-specific tasks like community question answering and knowledge-base question answering. Popular benchmark datasets for evaluation question answering systems include SQuAD, HotPotQA, bAbI, TriviaQA, WikiQA, and many others. Models for question answering are typically evaluated on metrics like EM and F1. Some recent top performing models are T5 and XLNet.\n",
      "( Image credit: SQuAD )\n",
      "[11/499]  Optical Character Recognition or Optical Character Reader (OCR) is the electronic or mechanical conversion of images of typed, handwritten or printed text into machine-encoded text, whether from a scanned document, a photo of a document, a scene-photo (for example the text on signs and billboards in a landscape photo, license plates in cars...) or from subtitle text superimposed on an image (for example: from a television broadcast)\n",
      "[12/499]  Image Captioning is the task of describing the content of an image in words. This task lies at the intersection of computer vision and natural language processing. Most image captioning systems use an encoder-decoder framework, where an input image is encoded into an intermediate representation of the information in the image, and then decoded into a descriptive text sequence. The most popular benchmarks are nocaps and COCO, and models are typically evaluated according to a BLEU or CIDER metric.\n",
      "( Image credit: Reflective Decoding Network for Image Captioning, ICCV'19)\n",
      "[13/499]  \n",
      "[14/499]  Person Re-Identification is a computer vision task in which the goal is to match a person's identity across different cameras or locations in a video or image sequence. It involves detecting and tracking a person and then using features such as appearance, body shape, and clothing to match their identity in different frames. The goal is to associate the same person across multiple non-overlapping camera views in a robust and efficient manner.\n",
      "[15/499]  Autonomous driving is the task of driving a vehicle without human conduction.\n",
      "Many of the state-of-the-art results can be found at more general task pages such as 3D Object Detection and Semantic Segmentation.\n",
      "(Image credit: Exploring the Limitations of Behavior Cloning for Autonomous Driving)\n",
      "[16/499]  Face Detection is a computer vision task that involves automatically identifying and locating human faces within digital images or videos. It is a fundamental technology that underpins many applications such as face recognition, face tracking, and facial analysis.\n",
      "( Image credit: insightface )\n",
      "[17/499]  This task has no description! Would you like to contribute one?\n",
      "[18/499]  Fine-Grained Image Classification is a task in computer vision where the goal is to classify images into subcategories within a larger category. For example, classifying different species of birds or different types of flowers. This task is considered to be fine-grained because it requires the model to distinguish between subtle differences in visual appearance and patterns, making it more challenging than regular image classification tasks.\n",
      "( Image credit: Looking for the Devil in the Details )\n",
      "[19/499]  Image Super-Resolution is a machine learning task where the goal is to increase the resolution of an image, often by a factor of 4x or more, while maintaining its content and details as much as possible. The end result is a high-resolution version of the original image. This task can be used for various applications such as improving image quality, enhancing visual detail, and increasing the accuracy of computer vision algorithms.\n",
      "[20/499]  Data augmentation involves techniques used for increasing the amount of data, based on different modifications, to expand the amount of examples in the original dataset. Data augmentation not only helps to grow the dataset but it also increases the diversity of the dataset. When training machine learning models, data augmentation acts as a regularizer and helps to avoid overfitting.\n",
      "Data augmentation techniques have been found useful in domains like NLP and computer vision. In computer vision, transformations like cropping, flipping, and rotation are used. In NLP, data augmentation techniques can include swapping, deletion, random insertion, among others.\n",
      "Further readings:\n",
      "A Survey of Data Augmentation Approaches for NLP\n",
      "A survey on Image Data Augmentation for Deep Learning\n",
      "( Image credit: Albumentations )\n",
      "[21/499]  Object recognition is a computer vision technique for detecting + classifying objects in images or videos. Since this is a combined task of object detection plus image classification, the state-of-the-art tables are recorded for each component task here and here.\n",
      "( Image credit: Tensorflow Object Detection API )\n",
      "[22/499]  Action Recognition is a computer vision task that involves recognizing human actions in videos or images. The goal is to classify and categorize the actions being performed in the video or image into a predefined set of action classes.\n",
      "In the video domain, it is an open question whether training an action classification network on a sufficiently large dataset, will give a similar boost in performance when applied to a different temporal task or dataset. The challenges of building video datasets has meant that most popular benchmarks for action recognition are small, having on the order of 10k videos.\n",
      "Please note some benchmarks may be located in the Action Classification or Video Classification tasks, e.g. Kinetics-400.\n",
      "[23/499]  Medical Image Segmentation is a computer vision task that involves dividing an medical image into multiple segments, where each segment represents a different object or structure of interest in the image. The goal of medical image segmentation is to provide a precise and accurate representation of the objects of interest within the image, typically for the purpose of diagnosis, treatment planning, and quantitative analysis.\n",
      "( Image credit: IVD-Net )\n",
      "[24/499]  Ability to understand actions and reasoning associated with any visual images\n",
      "[25/499]  Classification is the task of categorizing a set of data into predefined classes or groups. The aim of classification is to train a model to correctly predict the class or group of new, unseen data. The model is trained on a labeled dataset where each instance is assigned a class label. The learning algorithm then builds a mapping between the features of the data and the class labels. This mapping is then used to predict the class label of new, unseen data points. The quality of the prediction is usually evaluated using metrics such as accuracy, precision, and recall.\n",
      "[26/499]  Image-to-Image Translation is a task in computer vision and machine learning where the goal is to learn a mapping between an input image and an output image, such that the output image can be used to perform a specific task, such as style transfer, data augmentation, or image restoration.\n",
      "( Image credit: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks )\n",
      "[27/499]  Anomaly Detection is a binary classification identifying unusual or unexpected patterns in a dataset, which deviate significantly from the majority of the data. The goal of anomaly detection is to identify such anomalies, which could represent errors, fraud, or other types of unusual events, and flag them for further investigation.\n",
      "[Image source]: GAN-based Anomaly Detection in Imbalance Problems\n",
      "[28/499]  3D Human Pose Estimation is a computer vision task that involves estimating the 3D positions and orientations of body joints and bones from 2D images or videos. The goal is to reconstruct the 3D pose of a person in real-time, which can be used in a variety of applications, such as virtual reality, human-computer interaction, and motion analysis.\n",
      "[29/499]  Scene Understanding is something that to understand a scene. For instance, iPhone has function that help eye disabled person to take a photo by discribing what the camera sees. This is an example of Scene Understanding.\n",
      "[30/499]  Unsupervised Domain Adaptation is a learning framework to transfer knowledge learned from source domains with a large number of annotated training examples to target domains with unlabeled data only.\n",
      "Source: Domain-Specific Batch Normalization for Unsupervised Domain Adaptation\n",
      "[31/499]  Facial Expression Recognition (FER) is a computer vision task aimed at identifying and categorizing emotional expressions depicted on a human face. The goal is to automate the process of determining emotions in real-time, by analyzing the various features of a face such as eyebrows, eyes, mouth, and other features, and mapping them to a set of emotions such as anger, fear, surprise, sadness and happiness.\n",
      "( Image credit: DeXpression )\n",
      "[32/499]  Image source: Handwriting Recognition of Historical Documents with few labeled data\n",
      "[33/499]  Few-Shot Image Classification is a computer vision task that involves training machine learning models to classify images into predefined categories using only a few labeled examples of each category (typically < 6 examples). The goal is to enable models to recognize and classify new images with minimal supervision and limited data, without having to train on large datasets. (typically < 6 examples)\n",
      "( Image credit: Learning Embedding Adaptation for Few-Shot Learning )\n",
      "[34/499]  The goal of Metric Learning is to learn a representation function that maps objects into an embedded space. The distance in the embedded space should preserve the objects’ similarity — similar objects get close and dissimilar objects get far away. Various loss functions have been developed for Metric Learning. For example, the contrastive loss guides the objects from the same class to be mapped to the same point and those from different classes to be mapped to different points whose distances are larger than a margin. Triplet loss is also popular, which requires the distance between the anchor sample and the positive sample to be smaller than the distance between the anchor sample and the negative sample.\n",
      "Source: Road Network Metric Learning for Estimated Time of Arrival\n",
      "[35/499]  Object tracking is the task of taking an initial set of object detections, creating a unique ID for each of the initial detections, and then tracking each of the objects as they move around frames in a video, maintaining the ID assignment. State-of-the-art methods involve fusing data from RGB and event-based cameras to produce more reliable object tracking. CNN-based models using only RGB images as input are also effective. The most popular benchmark is OTB. There are several evaluation metrics specific to object tracking, including HOTA, MOTA, IDF1, and Track-mAP.\n",
      "( Image credit: Towards-Realtime-MOT )\n",
      "[36/499]  This task has no description! Would you like to contribute one?\n",
      "[37/499]  Image credit: GSNet: Joint Vehicle Pose and Shape Reconstruction with Geometrical and Scene-aware Supervision , ECCV'20\n",
      "[38/499]  Neural Architecture Search (NAS) learns a modular architecture which can be transferred from a small dataset to a large dataset. The method does this by reducing the problem of learning best convolutional architectures to the problem of learning a small convolutional cell. The cell can then be stacked in series to handle larger images and more complex datasets.\n",
      "Note that this refers to the original method referred to as NAS - there is also a broader category of methods called \"neural architecture search\".\n",
      "Source:\n",
      "Learning Transferable Architectures for Scalable Image Recognition\n",
      "Read Paper\n",
      "See Code\n",
      "[39/499]  3D Object Detection is a task in computer vision where the goal is to identify and locate objects in a 3D environment based on their shape, location, and orientation. It involves detecting the presence of objects and determining their location in the 3D space in real-time. This task is crucial for applications such as autonomous vehicles, robotics, and augmented reality.\n",
      "( Image credit: AVOD )\n",
      "[40/499]  \n",
      "[41/499]  Few-Shot Learning is an example of meta-learning, where a learner is trained on several related tasks, during the meta-training phase, so that it can generalize well to unseen (but related) tasks with just few examples, during the meta-testing phase. An effective approach to the Few-Shot Learning problem is to learn a common representation for various tasks and train task specific classifiers on top of this representation.\n",
      "Source: Penalty Method for Inversion-Free Deep Bilevel Optimization\n",
      "[42/499]  The goal of Object Counting task is to count the number of object instances in a single image or video sequence. It has many real-world applications such as traffic flow monitoring, crowdedness estimation, and product counting.\n",
      "Source: Learning to Count Objects with Few Exemplar Annotations\n",
      "[43/499]  Models that partition the dataset into semantically meaningful clusters without having access to the ground truth labels.\n",
      "Image credit: ImageNet clustering results of SCAN: Learning to Classify Images without Labels (ECCV 2020)\n",
      "[44/499]  Zero-shot learning (ZSL) is a model's ability to detect classes never seen during training. The condition is that the classes are not known during supervised learning.\n",
      "Earlier work in zero-shot learning use attributes in a two-step approach to infer unknown classes. In the computer vision context, more recent advances learn mappings from image feature space to semantic space. Other approaches learn non-linear multimodal embeddings. In the modern NLP context, language models can be evaluated on downstream tasks without fine tuning.\n",
      "Benchmark datasets for zero-shot learning include aPY, AwA, and CUB, among others.\n",
      "( Image credit: Prototypical Networks for Few shot Learning in PyTorch )\n",
      "Further readings:\n",
      "Zero-Shot Learning -- A Comprehensive Evaluation of the Good, the Bad and the Ugly\n",
      "Zero-Shot Learning in Modern NLP\n",
      "Zero-Shot Learning for Text Classification\n",
      "[45/499]  Facial anti-spoofing is the task of preventing false facial verification by using a photo, video, mask or a different substitute for an authorized person’s face. Some examples of attacks:\n",
      "Print attack: The attacker uses someone’s photo. The image is printed or displayed on a digital device.\n",
      "Replay/video attack: A more sophisticated way to trick the system, which usually requires a looped video of a victim’s face. This approach ensures behaviour and facial movements to look more ‘natural’ compared to holding someone’s photo.\n",
      "3D mask attack: During this type of attack, a mask is used as the tool of choice for spoofing. It’s an even more sophisticated attack than playing a face video. In addition to natural facial movements, it enables ways to deceive some extra layers of protection such as depth sensors.\n",
      "( Image credit: Learning Generalizable and Identity-Discriminative Representations for Face Anti-Spoofing )\n",
      "[46/499]  Image Inpainting is a task of reconstructing missing regions in an image. It is an important problem in computer vision and an essential functionality in many imaging and graphics applications, e.g. object removal, image restoration, manipulation, re-targeting, compositing, and image-based rendering.\n",
      "Source: High-Resolution Image Inpainting with Iterative Confidence Feedback and Guided Upsampling\n",
      "Image source: High-Resolution Image Inpainting with Iterative Confidence Feedback and Guided Upsampling\n",
      "[47/499]  Synthesize a target image with an arbitrary target camera pose from given source images and their camera poses.\n",
      "( Image credit: Multi-view to Novel view: Synthesizing novel views with Self-Learned Confidence )\n",
      "[48/499]  Optical Flow Estimation is a computer vision task that involves computing the motion of objects in an image or a video sequence. The goal of optical flow estimation is to determine the movement of pixels or features in the image, which can be used for various applications such as object tracking, motion analysis, and video compression.\n",
      "Approaches for optical flow estimation include correlation-based, block-matching, feature tracking, energy-based, and more recently gradient-based.\n",
      "Further readings:\n",
      "Optical Flow Estimation\n",
      "Performance of Optical Flow Techniques\n",
      "Definition source: Devon: Deformable Volume Network for Learning Optical Flow\n",
      "Image credit: Optical Flow Estimation\n",
      "[49/499]  Panoptic Segmentation is a computer vision task that combines semantic segmentation and instance segmentation to provide a comprehensive understanding of the scene. The goal of panoptic segmentation is to segment the image into semantically meaningful parts or regions, while also detecting and distinguishing individual instances of objects within those regions.\n",
      "( Image credit: Detectron2 )\n",
      "[50/499]  See Scene Text Detection for leaderboards in this task.\n",
      "[51/499]  Face Verification is a machine learning task in computer vision that involves determining whether two facial images belong to the same person or not. The task involves extracting features from the facial images, such as the shape and texture of the face, and then using these features to compare and verify the similarity between the images.\n",
      "( Image credit: Pose-Robust Face Recognition via Deep Residual Equivariant Mapping )\n",
      "[52/499]  Multi-task learning aims to learn multiple different tasks simultaneously while maximizing performance on one or all of the tasks.\n",
      "( Image credit: Cross-stitch Networks for Multi-task Learning )\n",
      "[53/499]  Continual Learning (also known as Incremental Learning, Life-long Learning) is a concept to learn a model for a large number of tasks sequentially without forgetting knowledge obtained from the preceding tasks, where the data in the old tasks are not available anymore during training new ones.\n",
      "If not mentioned, the benchmarks here are Task-CL, where task-id is provided on validation.\n",
      "Source:\n",
      "Continual Learning by Asymmetric Loss Approximation with Single-Side Overestimation\n",
      "Three scenarios for continual learning\n",
      "Lifelong Machine Learning\n",
      "Continual lifelong learning with neural networks: A review\n",
      "[54/499]  Cross-Modal Retrieval is used for implementing a retrieval task across different modalities. such as image-text, video-text, and audio-text Cross-Modal Retrieval. The main challenge of Cross-Modal Retrieval is the modality gap and the key solution of Cross-Modal Retrieval is to generate new representations from different modalities in the shared subspace, such that new generated features can be applied in the computation of distance metrics, such as cosine distance and Euclidean distance.\n",
      "Source: Deep Triplet Neural Networks with Cluster-CCA for Audio-Visual Cross-modal Retrieval\n",
      "[55/499]  The goal of Density Estimation is to give an accurate description of the underlying probabilistic density distribution of an observable data set with unknown density.\n",
      "Source: Contrastive Predictive Coding Based Feature for Automatic Speaker Verification\n",
      "[56/499]  Image Denoising is a computer vision task that involves removing noise from an image. Noise can be introduced into an image during acquisition or processing, and can reduce image quality and make it difficult to interpret. Image denoising techniques aim to restore an image to its original quality by reducing or removing the noise, while preserving the important features of the image.\n",
      "( Image credit: Wide Inference Network for Image Denoising via Learning Pixel-distribution Prior )\n",
      "[57/499]  Monocular Depth Estimation is the task of estimating the depth value (distance relative to the camera) of each pixel given a single (monocular) RGB image. This challenging task is a key prerequisite for determining scene understanding for applications such as 3D scene reconstruction, autonomous driving, and AR. State-of-the-art methods usually fall into one of two categories: designing a complex network that is powerful enough to directly regress the depth map, or splitting the input into bins or windows to reduce computational complexity. The most popular benchmarks are the KITTI and NYUv2 datasets. Models are typically evaluated using RMSE or absolute relative error.\n",
      "Source: Defocus Deblurring Using Dual-Pixel Data\n",
      "[58/499]  Multi-Label Classification is the supervised learning problem where an instance may be associated with multiple labels. This is an extension of single-label classification (i.e., multi-class, or binary) where each instance is only associated with a single class label.\n",
      "Source: Deep Learning for Multi-label Classification\n",
      "[59/499]  Object Localization is the task of locating an instance of a particular object category in an image, typically by specifying a tightly cropped bounding box centered on the instance. An object proposal specifies a candidate bounding box, and an object proposal is said to be a correct localization if it sufficiently overlaps a human-labeled “ground-truth” bounding box for the given object. In the literature, the “Object Localization” task is to locate one instance of an object category, whereas “object detection” focuses on locating all instances of a category in a given image.\n",
      "Source: Fast On-Line Kernel Density Estimation for Active Object Localization\n",
      "[60/499]  This task has no description! Would you like to contribute one?\n",
      "[61/499]  Super-Resolution is a task in computer vision that involves increasing the resolution of an image or video by generating missing high-frequency details from low-resolution input. The goal is to produce an output image with a higher resolution than the input image, while preserving the original content and structure.\n",
      "( Credit: MemNet )\n",
      "[62/499]  Visual Localization is the problem of estimating the camera pose of a given image relative to a visual representation of a known scene.\n",
      "Source: Fine-Grained Segmentation Networks: Self-Supervised Segmentation for Improved Long-Term Visual Localization\n",
      "[63/499]  Visual Odometry is an important area of information fusion in which the central aim is to estimate the pose of a robot using data collected by visual sensors.\n",
      "Source: Bi-objective Optimization for Robust RGB-D Visual Odometry\n",
      "[64/499]  This is an approach to solve a diverse set of tasks in a data efficient manner by disentangling (or isolating ) the underlying structure of the main problem into disjoint parts of its representations. This disentanglement can be done by focussing on the \"transformation\" properties of the world(main problem)\n",
      "[65/499]  The idea of Domain Generalization is to learn from one or multiple training domains, to extract a domain-agnostic model which can be applied to an unseen domain\n",
      "Source: Diagram Image Retrieval using Sketch-Based Deep Learning and Transfer Learning\n",
      "[66/499]  Face alignment is the task of identifying the geometric structure of faces in digital images, and attempting to obtain a canonical alignment of the face based on translation, scale, and rotation.\n",
      "( Image credit: 3DDFA_V2 )\n",
      "[67/499]  Hand pose estimation is the task of finding the joints of the hand from an image or set of video frames.\n",
      "( Image credit: Pose-REN )\n",
      "[68/499]  This task has no description! Would you like to contribute one?\n",
      "[69/499]  What is Human Pose Estimation? Human pose estimation is the process of estimating the configuration of the body (pose) from a single, typically monocular, image. Background. Human pose estimation is one of the key problems in computer vision that has been studied for well over 15 years. The reason for its importance is the abundance of applications that can benefit from such a technology. For example, human pose estimation allows for higher-level reasoning in the context of human-computer interaction and activity recognition; it is also one of the basic building blocks for marker-less motion capture (MoCap) technology. MoCap technology is useful for applications ranging from character animation to clinical analysis of gait pathologies.\n",
      "[70/499]  Crowd Counting is a task to count people in image. It is mainly used in real-life for automated public monitoring such as surveillance and traffic control. Different from object detection, Crowd Counting aims at recognizing arbitrarily sized targets in various situations including sparse and cluttering scenes at the same time.\n",
      "Source: Deep Density-aware Count Regressor\n",
      "[71/499]  Facial Landmark Detection is a computer vision task that involves detecting and localizing specific points or landmarks on a face, such as the eyes, nose, mouth, and chin. The goal is to accurately identify these landmarks in images or videos of faces in real-time and use them for various applications, such as face recognition, facial expression analysis, and head pose estimation.\n",
      "( Image credit: Style Aggregated Network for Facial Landmark Detection )\n",
      "[72/499]  Lesion segmentation is the task of segmenting out lesions from other objects in medical based images.\n",
      "( Image credit: D-UNet )\n",
      "[73/499]  Long-tailed learning, one of the most challenging problems in visual recognition, aims to train well-performing models from a large number of images that follow a long-tailed class distribution.\n",
      "[74/499]  Pedestrian detection is the task of detecting pedestrians from a camera.\n",
      "Further state-of-the-art results (e.g. on the KITTI dataset) can be found at 3D Object Detection.\n",
      "( Image credit: High-level Semantic Feature Detection: A New Perspective for Pedestrian Detection )\n",
      "[75/499]  Quantization is a promising technique to reduce the computation cost of neural network training, which can replace high-cost floating-point numbers (e.g., float32) with low-cost fixed-point numbers (e.g., int8/int16).\n",
      "Source: Adaptive Precision Training: Quantify Back Propagation in Neural Networks with Fixed-point Numbers\n",
      "[76/499]  Saliency Detection is a preprocessing step in computer vision which aims at finding salient objects in an image.\n",
      "Source: An Unsupervised Game-Theoretic Approach to Saliency Detection\n",
      "[77/499]  Self-Supervised Learning refers to a category of methods where we learn representations in a self-supervised way (i.e without labels). These methods generally involve a pretext task that is solved to learn a good representation and a loss function to learn with. Below you can find a continuously updating list of self-supervised methods.\n",
      "[78/499]  Semi-supervised image classification leverages unlabelled data as well as labelled data to increase classification performance.\n",
      "You may want to read some blog posts to get an overview before reading the papers and checking the leaderboards:\n",
      "An overview of proxy-label approaches for semi-supervised learning - Sebastian Ruder\n",
      "Semi-Supervised Learning in Computer Vision - Amit Chaudhary\n",
      "( Image credit: Self-Supervised Semi-Supervised Learning )\n",
      "[79/499]  Stereo Matching is one of the core technologies in computer vision, which recovers 3D structures of real world from 2D images. It has been widely used in areas such as autonomous driving, augmented reality and robotics navigation. Given a pair of rectified stereo images, the goal of Stereo Matching is to compute the disparity for each pixel in the reference image, where disparity is defined as the horizontal displacement between a pair of corresponding pixels in the left and right images.\n",
      "Source: Adaptive Unimodal Cost Volume Filtering for Deep Stereo Matching\n",
      "[80/499]  Video Prediction is the task of predicting future frames given past video frames.\n",
      "Gif credit: MAGVIT\n",
      "Source: Photo-Realistic Video Prediction on Natural Videos of Largely Changing Frames\n",
      "[81/499]  Visual Object Tracking is an important research topic in computer vision, image understanding and pattern recognition. Given the initial state (centre location and scale) of a target in the first frame of a video sequence, the aim of Visual Object Tracking is to automatically obtain the states of the object in the subsequent video frames.\n",
      "Source: Learning Adaptive Discriminative Correlation Filters via Temporal Consistency Preserving Spatial Feature Selection for Robust Visual Object Tracking\n",
      "[82/499]  Age Estimation is the task of estimating the age of a person from an image some other kind of data.\n",
      "( Image credit: BridgeNet )\n",
      "[83/499]  Autonomous vehicles is the task of making a vehicle that can guide itself without human conduction.\n",
      "Many of the state-of-the-art results can be found at more general task pages such as 3D Object Detection and Semantic Segmentation.\n",
      "( Image credit: GSNet: Joint Vehicle Pose and Shape Reconstruction with Geometrical and Scene-aware Supervision )\n",
      "[84/499]  Denoising is a task in image processing and computer vision that aims to remove or reduce noise from an image. Noise can be introduced into an image due to various reasons, such as camera sensor limitations, lighting conditions, and compression artifacts. The goal of denoising is to recover the original image, which is considered to be noise-free, from a noisy observation.\n",
      "( Image credit: Beyond a Gaussian Denoiser )\n",
      "[85/499]  Human-Object Interaction (HOI) detection is a task of identifying \"a set of interactions\" in an image, which involves the i) localization of the subject (i.e., humans) and target (i.e., objects) of interaction, and ii) the classification of the interaction labels.\n",
      "[86/499]  Image Segmentation is a computer vision task that involves dividing an image into multiple segments or regions, each of which corresponds to a different object or part of an object. The goal of image segmentation is to assign a unique label or category to each pixel in the image, so that pixels with similar attributes are grouped together.\n",
      "[87/499]  Scene Classification is a task in which scenes from photographs are categorically classified. Unlike object classification, which focuses on classifying prominent objects in the foreground, Scene Classification uses the layout of objects within the scene, in addition to the ambient context, for classification.\n",
      "Source: Scene classification with Convolutional Neural Networks\n",
      "[88/499]  Simultaneous localization and mapping (SLAM) is the task of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.\n",
      "( Image credit: ORB-SLAM2 )\n",
      "[89/499]  Skeleton-based Action Recognition is a computer vision task that involves recognizing human actions from a sequence of 3D skeletal joint data captured from sensors such as Microsoft Kinect, Intel RealSense, and wearable devices. The goal of skeleton-based action recognition is to develop algorithms that can understand and classify human actions from skeleton data, which can be used in various applications such as human-computer interaction, sports analysis, and surveillance.\n",
      "( Image credit: View Adaptive Neural Networks for High Performance Skeleton-based Human Action Recognition )\n",
      "[90/499]  Trajectory Prediction is the problem of predicting the short-term (1-3 seconds) and long-term (3-5 seconds) spatial coordinates of various road-agents such as cars, buses, pedestrians, rickshaws, and animals, etc. These road-agents have different dynamic behaviors that may correspond to aggressive or conservative driving styles.\n",
      "Source: Forecasting Trajectory and Behavior of Road-Agents Using Spectral Clustering in Graph-LSTMs\n",
      "[91/499]  The objective of Unsupervised Anomaly Detection is to detect previously unseen rare objects or events without any prior knowledge about these. The only information available is that the percentage of anomalies in the dataset is small, usually less than 1%. Since anomalies are rare and unknown to the user at training time, anomaly detection in most cases boils down to the problem of modelling the normal data distribution and defining a measurement in this space in order to classify samples as anomalous or normal. In high-dimensional data such as images, distances in the original space quickly lose descriptive power (curse of dimensionality) and a mapping to some more suitable space is required.\n",
      "Source: Unsupervised Learning of Anomaly Detection from Contaminated Image Data using Simultaneous Encoder Training\n",
      "[92/499]  Image: Zimmerman et l\n",
      "[93/499]  Common sense reasoning tasks are intended to require the model to go beyond pattern recognition. Instead, the model should use \"common sense\" or world knowledge to make inferences.\n",
      "[94/499]  Gaze Estimation is a task to predict where a person is looking at given the person’s full face. The task contains two directions: 3-D gaze vector and 2-D gaze position estimation. 3-D gaze vector estimation is to predict the gaze vector, which is usually used in the automotive safety. 2-D gaze position estimation is to predict the horizontal and vertical coordinates on a 2-D screen, which allows utilizing gaze point to control a cursor for human-machine interaction.\n",
      "Source: A Generalized and Robust Method Towards Practical Gaze Estimation on Smart Phone\n",
      "[95/499]  Image Compression is an application of data compression for digital images to lower their storage and/or transmission requirements.\n",
      "Source: Variable Rate Deep Image Compression With a Conditional Autoencoder\n",
      "[96/499]  Multi-Object Tracking is a task in computer vision that involves detecting and tracking multiple objects within a video sequence. The goal is to identify and locate objects of interest in each frame and then associate them across frames to keep track of their movements over time. This task is challenging due to factors such as occlusion, motion blur, and changes in object appearance, and is typically solved using algorithms that integrate object detection and data association techniques.\n",
      "[97/499]  Object detection in indoor scenes is the task of performing object detection within an indoor environment.\n",
      "( Image credit: Faster Bounding Box Annotation for Object Detection in Indoor Scenes )\n",
      "[98/499]  RGB Salient object detection is a task-based on a visual attention mechanism, in which algorithms aim to explore objects or regions more attentive than the surrounding areas on the scene or RGB images.\n",
      "( Image credit: Attentive Feedback Network for Boundary-Aware Salient Object Detection )\n",
      "[99/499]  Scene Text Detection is a computer vision task that involves automatically identifying and localizing text within natural images or videos. The goal of scene text detection is to develop algorithms that can robustly detect and and label text with bounding boxes in uncontrolled and complex environments, such as street signs, billboards, or license plates.\n",
      "Source: ContourNet: Taking a Further Step toward Accurate Arbitrary-shaped Scene Text Detection\n",
      "[100/499]  Text-to-Image Generation is a task in computer vision and natural language processing where the goal is to generate an image that corresponds to a given textual description. This involves converting the text input into a meaningful representation, such as a feature vector, and then using this representation to generate an image that matches the description.\n",
      "[101/499]  Vehicle re-identification is the task of identifying the same vehicle across multiple cameras.\n",
      "( Image credit: A Two-Stream Siamese Neural Network for Vehicle Re-Identification by Using Non-Overlapping Cameras )\n",
      "[102/499]  Video object segmentation is a binary labeling problem aiming to separate foreground object(s) from the background region of a video.\n",
      "For leaderboards please refer to the different subtasks.\n",
      "[103/499]  A crucial task of Video Understanding is to recognise and localise (in space and time) different actions or events appearing in the video.\n",
      "Source: Action Detection from a Robot-Car Perspective\n",
      "[104/499]  Visual Place Recognition is the task of matching a view of a place with a different view of the same place taken at a different time.\n",
      "Source: Visual place recognition using landmark distribution descriptors\n",
      "Image credit: Visual place recognition using landmark distribution descriptors\n",
      "[105/499]  Weakly Supervised Object Detection (WSOD) is the task of training object detectors with only image tag supervisions.\n",
      "( Image credit: Soft Proposal Networks for Weakly Supervised Object Localization )\n",
      "[106/499]  3D Face Reconstruction is a computer vision task that involves creating a 3D model of a human face from a 2D image or a set of images. The goal of 3D face reconstruction is to reconstruct a digital 3D representation of a person's face, which can be used for various applications such as animation, virtual reality, and biometric identification.\n",
      "( Image credit: 3DDFA_V2 )\n",
      "[107/499]  Image: OccuSeg\n",
      "[108/499]  3D Semantic Segmentation is a computer vision task that involves dividing a 3D point cloud or 3D mesh into semantically meaningful parts or regions. The goal of 3D semantic segmentation is to identify and label different objects and parts within a 3D scene, which can be used for applications such as robotics, autonomous driving, and augmented reality.\n",
      "[109/499]  The term “computed tomography”, or CT, refers to a computerized x-ray imaging procedure in which a narrow beam of x-rays is aimed at a patient and quickly rotated around the body, producing signals that are processed by the machine's computer to generate cross-sectional images—or “slices”—of the body.\n",
      "( Image credit: Liver Lesion Detection from Weakly-labeled Multi-phase CT Volumes with a Grouped Single Shot MultiBox Detector )\n",
      "[110/499]  Decision Making is a complex task that involves analyzing data (of different level of abstraction) from disparate sources and with different levels of certainty, merging the information by weighing in on some data source more than other, and arriving at a conclusion by exploring all possible alternatives.\n",
      "Source: Complex Events Recognition under Uncertainty in a Sensor Network\n",
      "[111/499]  This task has no description! Would you like to contribute one?\n",
      "[112/499]  Gesture Recognition is an active field of research with applications such as automatic recognition of sign language, interaction of humans and robots or for new ways of controlling video games.\n",
      "Source: Gesture Recognition in RGB Videos Using Human Body Keypoints and Dynamic Time Warping\n",
      "[113/499]  The inverse of handwriting recognition. From text generate and image of handwriting (offline) of trajectory of handwriting (online).\n",
      "[114/499]  This task has no description! Would you like to contribute one?\n",
      "[115/499]  Image registration is the process of transforming different sets of data into one coordinate system. Data may be multiple photographs, data from different sensors, times, depths, or viewpoints. It is used in computer vision, medical imaging, and compiling and analyzing images and data from satellites. Registration is necessary in order to be able to compare or integrate the data obtained from these different measurements.\n",
      "Source: Image registration | Wikipedia\n",
      "( Image credit: Kornia )\n",
      "[116/499]  Image Restoration is a family of inverse problems for obtaining a high quality image from a corrupted input image. Corruption may occur due to the image-capture process (e.g., noise, lens blur), post-processing (e.g., JPEG compression), or photography in non-ideal conditions (e.g., haze, motion blur).\n",
      "Source: Blind Image Restoration without Prior Knowledge\n",
      "[117/499]  Lane Detection is a computer vision task that involves identifying the boundaries of driving lanes in a video or image of a road scene. The goal is to accurately locate and track the lane markings in real-time, even in challenging conditions such as poor lighting, glare, or complex road layouts.\n",
      "Lane detection is an important component of advanced driver assistance systems (ADAS) and autonomous vehicles, as it provides information about the road layout and the position of the vehicle within the lane, which is crucial for navigation and safety. The algorithms typically use a combination of computer vision techniques, such as edge detection, color filtering, and Hough transforms, to identify and track the lane markings in a road scene.\n",
      "( Image credit: End-to-end Lane Detection )\n",
      "[118/499]  Medical Diagnosis is the process of identifying the disease a patient is affected by, based on the assessment of specific risk factors, signs, symptoms and results of exams.\n",
      "Source: A probabilistic network for the diagnosis of acute cardiopulmonary diseases\n",
      "[119/499]  Multimodal deep learning is a type of deep learning that combines information from multiple modalities, such as text, image, audio, and video, to make more accurate and comprehensive predictions. It involves training deep neural networks on data that includes multiple types of information and using the network to make predictions based on this combined data.\n",
      "One of the key challenges in multimodal deep learning is how to effectively combine information from multiple modalities. This can be done using a variety of techniques, such as fusing the features extracted from each modality, or using attention mechanisms to weight the contribution of each modality based on its importance for the task at hand.\n",
      "Multimodal deep learning has many applications, including image captioning, speech recognition, natural language processing, and autonomous vehicles. By combining information from multiple modalities, multimodal deep learning can improve the accuracy and robustness of models, enabling them to perform better in real-world scenarios where multiple types of information are present.\n",
      "[120/499]  Detect out-of-distribution or anomalous examples.\n",
      "[121/499]  Prompt engineering is a practice of creating a large number of prompts to more efficiently extract information from Language Models.\n",
      "[122/499]  Supervised image classification with tens to hundreds of labeled training examples.\n",
      "[123/499]  Style Transfer is a technique in computer vision and graphics that involves generating a new image by combining the content of one image with the style of another image. The goal of style transfer is to create an image that preserves the content of the original image while applying the visual style of another image.\n",
      "( Image credit: A Neural Algorithm of Artistic Style )\n",
      "[124/499]  Text Generation is the task of generating text with the goal of appearing indistinguishable to human-written text. This task if more formally known as \"natural language generation\" in the literature.\n",
      "Text generation can be addressed with Markov processes or deep generative models like LSTMs. Recently, some of the most advanced methods for text generation include BART, GPT and other GAN-based approaches. Text generation systems are evaluated either through human ratings or automatic evaluation metrics like METEOR, ROUGE, and BLEU.\n",
      "Further readings:\n",
      "The survey: Text generation models in deep learning\n",
      "Modern Methods for Text Generation\n",
      "( Image credit: Adversarial Ranking for Language Generation )\n",
      "[125/499]  Transfer Learning is a machine learning technique where a model trained on one task is re-purposed and fine-tuned for a related, but different task. The idea behind transfer learning is to leverage the knowledge learned from a pre-trained model to solve a new, but related problem. This can be useful in situations where there is limited data available to train a new model from scratch, or when the new task is similar enough to the original task that the pre-trained model can be adapted to the new problem with only minor modifications.\n",
      "( Image credit: Subodh Malgonde )\n",
      "[126/499]  Tumor Segmentation is the task of identifying the spatial location of a tumor. It is a pixel-level prediction where each pixel is classified as a tumor or background. The most popular benchmark for this task is the BraTS dataset. The models are typically evaluated with the Dice Score metric.\n",
      "[127/499]  Models that learn to segment each image (i.e. assign a class to every pixel) without seeing the ground truth labels.\n",
      "( Image credit: SegSort: Segmentation by Discriminative Sorting of Segments )\n",
      "[128/499]  Visual Navigation is the problem of navigating an agent, e.g. a mobile robot, in an environment using camera input only. The agent is given a target image (an image it will see from the target position), and its goal is to move from its current position to the target by applying a sequence of actions, based on the camera observations only.\n",
      "Source: Vision-based Navigation Using Deep Reinforcement Learning\n",
      "[129/499]  Animal pose estimation is the task of identifying the pose of an animal.\n",
      "( Image credit: Using DeepLabCut for 3D markerless pose estimation across species and behaviors )\n",
      "[130/499]  This task has no description! Would you like to contribute one?\n",
      "[131/499]  Conditional image generation is the task of generating new images from a dataset conditional on their class.\n",
      "( Image credit: PixelCNN++ )\n",
      "[132/499]  This task has no description! Would you like to contribute one?\n",
      "[133/499]  This task has no description! Would you like to contribute one?\n",
      "[134/499]  Generalizable person re-identification refers to methods trained on a source dataset but directly evaluated on a target dataset without domain adaptation or transfer learning.\n",
      "[135/499]  This task has no description! Would you like to contribute one?\n",
      "[136/499]  This task has no description! Would you like to contribute one?\n",
      "[137/499]  ( Image credit: Densely Connected Pyramid Dehazing Network )\n",
      "[138/499]  Image Enhancement is basically improving the interpretability or perception of information in images for human viewers and providing ‘better’ input for other automated image processing techniques. The principal objective of Image Enhancement is to modify attributes of an image to make it more suitable for a given task and a specific observer.\n",
      "Source: A Comprehensive Review of Image Enhancement Techniques\n",
      "[139/499]  Keypoint Detection involves simultaneously detecting people and localizing their keypoints. Keypoints are the same thing as interest points. They are spatial locations, or points in the image that define what is interesting or what stand out in the image. They are invariant to image rotation, shrinkage, translation, distortion, and so on.\n",
      "( Image credit: PifPaf: Composite Fields for Human Pose Estimation; \"Learning to surf\" by fotologic, license: CC-BY-2.0 )\n",
      "[140/499]  This task has no description! Would you like to contribute one?\n",
      "[141/499]  This task has no description! Would you like to contribute one?\n",
      "[142/499]  Low-Light Image Enhancement is a computer vision task that involves improving the quality of images captured under low-light conditions. The goal of low-light image enhancement is to make images brighter, clearer, and more visually appealing, without introducing too much noise or distortion.\n",
      "[143/499]  Real-Time Object Detection is a computer vision task that involves identifying and locating objects of interest in real-time video sequences with fast inference while maintaining a base level of accuracy.\n",
      "This is typically solved using algorithms that combine object detection and tracking techniques to accurately detect and track objects in real-time. They use a combination of feature extraction, object proposal generation, and classification to detect and localize objects of interest.\n",
      "( Image credit: CenterNet )\n",
      "[144/499]  Semantic Segmentation is a computer vision task that involves assigning a semantic label to each pixel in an image. In Real-Time Semantic Segmentation, the goal is to perform this labeling quickly and accurately in real-time, allowing for the segmentation results to be used for tasks such as object recognition, scene understanding, and autonomous navigation.\n",
      "( Image credit: TorchSeg )\n",
      "[145/499]  The goal of Relational Reasoning is to figure out the relationships among different entities, such as image pixels, words or sentences, human skeletons or interactive moving agents.\n",
      "Source: Social-WaGDAT: Interaction-aware Trajectory Prediction via Wasserstein Graph Double-Attention Network\n",
      "[146/499]  A Benchmark for the: Robustness of Object Detection Models to Image Corruptions and Distortions\n",
      "To allow fair comparison of robustness enhancing methods all models have to use a standard ResNet50 backbone because performance strongly scales with backbone capacity. If requested an unrestricted category can be added later.\n",
      "Benchmark Homepage: https://github.com/bethgelab/robust-detection-benchmark\n",
      "Metrics:\n",
      "mPC [AP]: Mean Performance under Corruption [measured in AP]\n",
      "rPC [%]: Relative Performance under Corruption [measured in %]\n",
      "Test sets: Coco: val 2017; Pascal VOC: test 2007; Cityscapes: val;\n",
      "( Image credit: Benchmarking Robustness in Object Detection )\n",
      "[147/499]  Stochastic Optimization methods are used to optimize neural networks. We typically take a mini-batch of data, hence 'stochastic', and perform a type of gradient descent with this minibatch. Below you can find a continuously updating list of stochastic optimization algorithms.\n",
      "Subcategories\n",
      "1 Large Batch Optimization\n",
      "2 Momentum Rules\n",
      "[148/499]  Surface normal estimation deals with the task of predicting the surface orientation of the objects present inside a scene. Refer to Designing Deep Networks for Surface Normal Estimation (Wang et al.) to get a good overview of several design choices that led to the development of a CNN-based surface normal estimator.\n",
      "[149/499]  Image credit:Table Detection in the Wild: A Novel Diverse Table Detection Dataset and Method\n",
      "[150/499]  Text Classification is the task of assigning a sentence or document an appropriate category. The categories depend on the chosen dataset and can range from topics.\n",
      "Text Classification problems include emotion classification, news classification, citation intent classification, among others. Benchmark datasets for evaluating text classification capabilities include GLUE, AGNews, among others.\n",
      "In recent years, deep learning techniques like XLNet and RoBERTa have attained some of the biggest performance jumps for text classification problems.\n",
      "( Image credit: Text Classification Algorithms: A Survey )\n",
      "[151/499]  A segmentation task which does not utilise any human-level supervision for semantic segmentation except for a backbone which is initialised with features pre-trained with image-level labels.\n",
      "[152/499]  Image source: Visual Commonsense Reasoning\n",
      "[153/499]  Visual Tracking is an essential and actively researched problem in the field of computer vision with various real-world applications such as robotic services, smart surveillance systems, autonomous driving, and human-computer interaction. It refers to the automatic estimation of the trajectory of an arbitrary target object, usually specified by a bounding box in the first frame, as it moves around in subsequent video frames.\n",
      "Source: Learning Reinforced Attentional Representation for End-to-End Visual Tracking\n",
      "[154/499]  Image: monodepth2\n",
      "[155/499]  Image credit: GSNet: Joint Vehicle Pose and Shape Reconstruction with Geometrical and Scene-aware Supervision , ECCV'20\n",
      "[156/499]  Image: Zeng et al\n",
      "[157/499]  Human Activity Recognition is the problem of identifying events performed by humans given a video input. It is formulated as a binary (or multiclass) classification problem of outputting activity class labels. Activity Recognition is an important problem with many societal applications including smart surveillance, video search/retrieval, intelligent robots, and other monitoring systems.\n",
      "Source: Learning Latent Sub-events in Activity Videos Using Temporal Attention Filters\n",
      "[158/499]  Adversarial Robustness evaluates the vulnerabilities of machine learning models under various types of adversarial attacks.\n",
      "[159/499]  This task has no description! Would you like to contribute one?\n",
      "[160/499]  Covid-19 Diagnosis is the task of diagnosing the presence of COVID-19 in an individual with machine learning.\n",
      "[161/499]  This task has no description! Would you like to contribute one?\n",
      "[162/499]  Colorization is a self-supervision approach that relies on colorization as the pretext task in order to learn image representations.\n",
      "Source:\n",
      "Colorful Image Colorization\n",
      "Read Paper\n",
      "See Code\n",
      "[163/499]  Deblurring is a computer vision task that involves removing the blurring artifacts from images or videos to restore the original, sharp content. Blurring can be caused by various factors such as camera shake, fast motion, and out-of-focus objects, and can result in a loss of detail and quality in the captured images. The goal of deblurring is to produce a clear, high-quality image that accurately represents the original scene.\n",
      "( Image credit: Deblurring Face Images using Uncertainty Guided Multi-Stream Semantic Networks )\n",
      "[164/499]  DeepFake Detection is the task of detecting fake videos or images that have been generated using deep learning techniques. Deepfakes are created by using machine learning algorithms to manipulate or replace parts of an original video or image, such as the face of a person. The goal of deepfake detection is to identify such manipulations and distinguish them from real videos or images.\n",
      "Description source: DeepFakes: a New Threat to Face Recognition? Assessment and Detection\n",
      "Image source: DeepFakes: a New Threat to Face Recognition? Assessment and Detection\n",
      "[165/499]  The Depth Completion task is a sub-problem of depth estimation. In the sparse-to-dense depth completion problem, one wants to infer the dense depth map of a 3-D scene given an RGB image and its corresponding sparse reconstruction in the form of a sparse depth map obtained either from computational methods such as SfM (Strcuture-from-Motion) or active sensors such as lidar or structured light sensors.\n",
      "Source: LiStereo: Generate Dense Depth Maps from LIDAR and Stereo Imagery , Unsupervised Depth Completion from Visual Inertial Odometry\n",
      "[166/499]  Face swapping refers to the task of swapping faces between images or in an video, while maintaining the rest of the body and environment context.\n",
      "( Image credit: Swapped Face Detection using Deep Learning and Subjective Assessment )\n",
      "[167/499]  This task has no description! Would you like to contribute one?\n",
      "[168/499]  This task has no description! Would you like to contribute one?\n",
      "[169/499]  Graph Matching is the problem of finding correspondences between two sets of vertices while preserving complex relational information among them. Since the graph structure has a strong capacity to represent objects and robustness to severe deformation and outliers, it is frequently adopted to formulate various correspondence problems in the field of computer vision. Theoretically, the Graph Matching problem can be solved by exhaustively searching the entire solution space. However, this approach is infeasible in practice because the solution space expands exponentially as the size of input data increases. For that reason, previous studies have attempted to solve the problem by using various approximation techniques.\n",
      "Source: Consistent Multiple Graph Matching with Multi-layer Random Walks Synchronization\n",
      "[170/499]  Hyperspectral Image Classification is a task in the field of remote sensing and computer vision. It involves the classification of pixels in hyperspectral images into different classes based on their spectral signature. Hyperspectral images contain information about the reflectance of objects in hundreds of narrow, contiguous wavelength bands, making them useful for a wide range of applications, including mineral mapping, vegetation analysis, and urban land-use mapping. The goal of this task is to accurately identify and classify different types of objects in the image, such as soil, vegetation, water, and buildings, based on their spectral properties.\n",
      "( Image credit: Shorten Spatial-spectral RNN with Parallel-GRU for Hyperspectral Image Classification )\n",
      "[171/499]  This task has no description! Would you like to contribute one?\n",
      "[172/499]  This task has no description! Would you like to contribute one?\n",
      "[173/499]  Incremental learning aims to develop artificially intelligent systems that can continuously learn to address new tasks from new data while preserving knowledge learned from previously learned tasks.\n",
      "[174/499]  Information retrieval is the task of ranking a list of documents or search results in response to a query\n",
      "( Image credit: sudhanshumittal )\n",
      "[175/499]  Language Modeling is the task of predicting the next word or character in a document. This technique can be used to train language models that can further be applied to a wide range of natural language tasks like text generation, text classification, and question answering.\n",
      "The common types of language modeling techniques involve:\n",
      "N-gram Language Models\n",
      "Neural Langauge Models\n",
      "A model's language modeling capability is measured using cross-entropy and perplexity. Some datasets to evaluate language modeling are WikiText-103, One Billion Word, Text8, C4, among others.\n",
      "One of the most recent popular benchmarks to evaluate language modeling capabilities is called SuperGLUE.\n",
      "Some popular and notable state-of-the-art language models, include:\n",
      "GPT-3\n",
      "Megatron-LM\n",
      "BERT\n",
      "Check below for all state-of-the-art models.\n",
      "Here are some additional readings to go deeper on the task:\n",
      "Language Modeling - Lena Voita\n",
      "( Image credit: Exploring the Limits of Language Modeling )\n",
      "[176/499]  Learning with noisy labels means When we say \"noisy labels,\" we mean that an adversary has intentionally messed up the labels, which would have come from a \"clean\" distribution otherwise. This setting can also be used to cast learning from only positive and unlabeled data.\n",
      "[177/499]  License Plate Recognition is an image-processing technology used to identify vehicles by their license plates. This technology is used in various security and traffic applications.\n",
      "[178/499]  The Multi-Label Image Classification focuses on predicting labels for images in a multi-class classification problem where each image may belong to more than one class.\n",
      "[179/499]  Multiple Object Tracking is the problem of automatically identifying multiple objects in a video and representing them as a set of trajectories with high accuracy.\n",
      "Source: SOT for MOT\n",
      "[180/499]  Node Classification is a machine learning task in graph-based data analysis, where the goal is to assign labels to nodes in a graph based on the properties of nodes and the relationships between them.\n",
      "Node Classification models aim to predict non-existing node properties (known as the target property) based on other node properties. Typical models used for node classification consists of a large family of graph neural networks. Model performance can be measured using benchmark datasets like Cora, Citeseer, and Pubmed, among others, typically using Accuracy and F1.\n",
      "( Image credit: Fast Graph Representation Learning With PyTorch Geometric )\n",
      "[181/499]  This task has no description! Would you like to contribute one?\n",
      "[182/499]  Given an image and a corresponding caption, the Phrase Grounding task aims to ground each entity mentioned by a noun phrase in the caption to a region in the image.\n",
      "Source: Phrase Grounding by Soft-Label Chain Conditional Random Field\n",
      "[183/499]  Pose prediction is to predict future poses given a window of previous poses.\n",
      "[184/499]  This task has no description! Would you like to contribute one?\n",
      "[185/499]  \n",
      "[186/499]  Temporal Action Localization aims to detect activities in the video stream and output beginning and end timestamps. It is closely related to Temporal Action Proposal Generation.\n",
      "[187/499]  Models that learn to label each image (i.e. cluster the dataset into its ground truth classes) without seeing the ground truth labels.\n",
      "Image credit: ImageNet clustering results of SCAN: Learning to Classify Images without Labels (ECCV 2020)\n",
      "[188/499]  Vision-language navigation (VLN) is the task of navigating an embodied agent to carry out natural language instructions inside real 3D environments.\n",
      "( Image credit: Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout )\n",
      "[189/499]  Visual Dialog requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content. Specifically, given an image, a dialog history, and a follow-up question about the image, the task is to answer the question.\n",
      "[190/499]  Zero-shot object detection (ZSD) is the task of object detection where no visual training data is available for some of the target object classes.\n",
      "( Image credit: Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concepts )\n",
      "[191/499]  This task has no description! Would you like to contribute one?\n",
      "[192/499]  This task aims to solve absolute (camera-centric not root-relative) 3D human pose estimation.\n",
      "( Image credit: RootNet )\n",
      "[193/499]  This task has no description! Would you like to contribute one?\n",
      "[194/499]  This task has no description! Would you like to contribute one?\n",
      "[195/499]  \n",
      "[196/499]  Competitions with currently unpublished results:\n",
      "TrojAI\n",
      "[197/499]  Class-agnostic object detection aims to localize objects in images without specifying their categories.\n",
      "[198/499]  Dictionary Learning is an important problem in multiple areas, ranging from computational neuroscience, machine learning, to computer vision and image processing. The general goal is to find a good basis for given data. More formally, in the Dictionary Learning problem, also known as sparse coding, we are given samples of a random vector\n",
      "y\n",
      "∈\n",
      "R\n",
      "n\n",
      ", of the form\n",
      "y\n",
      "=\n",
      "A\n",
      "x\n",
      "where\n",
      "A\n",
      "is some unknown matrix in\n",
      "R\n",
      "n\n",
      "×\n",
      "m\n",
      ", called dictionary, and\n",
      "x\n",
      "is sampled from an unknown distribution over sparse vectors. The goal is to approximately recover the dictionary\n",
      "A\n",
      ".\n",
      "Source: Polynomial-time tensor decompositions with sum-of-squares\n",
      "[199/499]  \"Document Layout Analysis is performed to determine physical structure of a document, that is, to determine document components. These document components can consist of single connected components-regions [...] of pixels that are adjacent to form single regions [...] , or group of text lines. A text line is a group of characters, symbols, and words that are adjacent, “relatively close” to each other and through which a straight line can be drawn (usually with horizontal or vertical orientation).\" L. O'Gorman, \"The document spectrum for page layout analysis,\" in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 15, no. 11, pp. 1162-1173, Nov. 1993.\n",
      "Image credit: PubLayNet: largest dataset ever for document layout analysis\n",
      "[200/499]  Emotion Recognition is an important area of research to enable effective human-computer interaction. Human emotions can be detected using speech signal, facial expressions, body language, and electroencephalography (EEG). Source: Using Deep Autoencoders for Facial Expression Recognition\n",
      "[201/499]  Face sketch synthesis is the task of generating a sketch from an input face photo.\n",
      "( Image credit: High-Quality Facial Photo-Sketch Synthesis Using Multi-Adversarial Networks )\n",
      "[202/499]  Facial attribute classification is the task of classifying various attributes of a facial image - e.g. whether someone has a beard, is wearing a hat, and so on.\n",
      "( Image credit: Multi-task Learning of Cascaded CNN for Facial Attribute Classification )\n",
      "[203/499]  Few-Shot Object Detection is a computer vision task that involves detecting objects in images with limited training data. The goal is to train a model on a few examples of each object class and then use the model to detect objects in new images.\n",
      "[204/499]  Font recognition (also called visual font recognition or optical font recognition) is the task of identifying the font family or families used in images containing text. Understanding which fonts are used in text may, for example, help designers find the right style, as well as help select an optical character recognition engine or model that is a better fit for certain texts.\n",
      "[205/499]  ( Image credit: GaitSet: Regarding Gait as a Set for Cross-View Gait Recognition )\n",
      "[206/499]  Algorithms trying to solve the general task of classification.\n",
      "[207/499]  This task has no description! Would you like to contribute one?\n",
      "[208/499]  This task has no description! Would you like to contribute one?\n",
      "[209/499]  Estimating the head pose of a person is a crucial problem that has a large amount of applications such as aiding in gaze estimation, modeling attention, fitting 3D models to video and performing face alignment.\n",
      "( Image credit: FSA-Net: Learning Fine-Grained Structure Aggregation for Head Pose Estimation from a Single Image )\n",
      "[210/499]  Homography estimation is a technique used in computer vision and image processing to find the relationship between two images of the same scene, but captured from different viewpoints. It is used to align images, correct for perspective distortions, or perform image stitching. In order to estimate the homography, a set of corresponding points between the two images must be found, and a mathematical model must be fit to these points. There are various algorithms and techniques that can be used to perform homography estimation, including direct methods, RANSAC, and machine learning-based approaches.\n",
      "[211/499]  This task has no description! Would you like to contribute one?\n",
      "[212/499]  Determining the location of an image without GPS based on cross-view matching. In most of the cases a database of satellite images is used to match the ground images to them.\n",
      "[213/499]  Intrinsic Image Decomposition is the process of separating an image into its formation components such as reflectance (albedo) and shading (illumination). Reflectance is the color of the object, invariant to camera viewpoint and illumination conditions, whereas shading, dependent on camera viewpoint and object geometry, consists of different illumination effects, such as shadows, shading and inter-reflections. Using intrinsic images, instead of the original images, can be beneficial for many computer vision algorithms. For instance, for shape-from-shading algorithms, the shading images contain important visual cues to recover geometry, while for segmentation and detection algorithms, reflectance images can be beneficial as they are independent of confounding illumination effects. Furthermore, intrinsic images are used in a wide range of computational photography applications, such as material recoloring, relighting, retexturing and stylization.\n",
      "Source: CNN based Learning using Reflection and Retinex Models for Intrinsic Image Decomposition\n",
      "[214/499]  This task has no description! Would you like to contribute one?\n",
      "[215/499]  Meta-learning is a methodology considered with \"learning to learn\" machine learning algorithms.\n",
      "( Image credit: Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks )\n",
      "[216/499]  Multi-person pose estimation is the task of estimating the pose of multiple people in one frame.\n",
      "( Image credit: Human Pose Estimation with TensorFlow )\n",
      "[217/499]  Object proposal generation is a preprocessing technique that has been widely used in current object detection pipelines to guide the search of objects and avoid exhaustive sliding window search across images.\n",
      "( Image credit: Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation )\n",
      "[218/499]  Outlier Detection is a task of identifying a subset of a given data set which are considered anomalous in that they are unusual from other instances. It is one of the core data mining tasks and is central to many applications. In the security field, it can be used to identify potentially threatening users, in the manufacturing field it can be used to identify parts that are likely to fail.\n",
      "Source: Coverage-based Outlier Explanation\n",
      "[219/499]  Partial Domain Adaptation is a transfer learning paradigm, which manages to transfer relevant knowledge from a large-scale source domain to a small-scale target domain.\n",
      "Source: Deep Residual Correction Network for Partial Domain Adaptation\n",
      "[220/499]  Person Search is a task which aims at matching a specific person among a great number of whole scene images.\n",
      "Source: Re-ID Driven Localization Refinement for Person Search\n",
      "[221/499]  The federated learning setup presents numerous challenges including data heterogeneity (differences in data distribution), device heterogeneity (in terms of computation capabilities, network connection, etc.), and communication efficiency. Especially data heterogeneity makes it hard to learn a single shared global model that applies to all clients. To overcome these issues, Personalized Federated Learning (PFL) aims to personalize the global model for each client in the federation.\n",
      "[222/499]  The goal of Question Generation is to generate a valid and fluent question according to a given passage and the target answer. Question Generation can be used in many scenarios, such as automatic tutoring systems, improving the performance of Question Answering models and enabling chatbots to lead a conversation.\n",
      "Source: Generating Highly Relevant Questions\n",
      "[223/499]  RGB-D Salient object detection (SOD) aims at distinguishing the most visually distinctive objects or regions in a scene from the given RGB and Depth data. It has a wide range of applications, including video/image segmentation, object recognition, visual tracking, foreground maps evaluation, image retrieval, content-aware image editing, information discovery, photosynthesis, and weakly supervised semantic segmentation. Here, depth information plays an important complementary role in finding salient objects. Online benchmark: http://dpfan.net/d3netbenchmark.\n",
      "( Image credit: Rethinking RGB-D Salient Object Detection: Models, Data Sets, and Large-Scale Benchmarks, TNNLS20 )\n",
      "[224/499]  This task has no description! Would you like to contribute one?\n",
      "[225/499]  Retinal vessel segmentation is the task of segmenting vessels in retina imagery.\n",
      "( Image credit: LadderNet )\n",
      "[226/499]  Self-driving cars : the task of making a car that can drive itself without human guidance.\n",
      "( Image credit: Learning a Driving Simulator )\n",
      "[227/499]  This task has no description! Would you like to contribute one?\n",
      "[228/499]  This task has no description! Would you like to contribute one?\n",
      "[229/499]  This task has no description! Would you like to contribute one?\n",
      "[230/499]  This task has no description! Would you like to contribute one?\n",
      "[231/499]  The unsupervised scenario assumes that the user does not interact with the algorithm to obtain the segmentation masks. Methods should provide a set of object candidates with no overlapping pixels that span through the whole video sequence. This set of objects should contain at least the objects that capture human attention when watching the whole video sequence i.e objects that are more likely to be followed by human gaze.\n",
      "[232/499]  The goal of Video Inpainting is to fill in missing regions of a given video sequence with contents that are both spatially and temporally coherent. Video Inpainting, also known as video completion, has many real-world applications such as undesired object removal and video restoration.\n",
      "Source: Deep Flow-Guided Video Inpainting\n",
      "[233/499]  This task has no description! Would you like to contribute one?\n",
      "[234/499]  Virtual try-on of clothing or other items such as glasses and makeup. Most recent techniques use Generative Adversarial Networks.\n",
      "[235/499]  Image: Rahmani et al\n",
      "[236/499]  This task has no description! Would you like to contribute one?\n",
      "[237/499]  3D medical imaging segmentation is the task of segmenting medical objects of interest from 3D medical imaging.\n",
      "( Image credit: Elastic Boundary Projection for 3D Medical Image Segmentation )\n",
      "[238/499]  3D object recognition is the task of recognising objects from 3D data.\n",
      "Note that there are related tasks you can look at, such as 3D Object Detection which have more leaderboards.\n",
      "(Image credit: Look Further to Recognize Better)\n",
      "[239/499]  This task has no description! Would you like to contribute one?\n",
      "[240/499]  6D Pose Estimation using RGB refers to the task of determining the six degree-of-freedom (6D) pose of an object in 3D space based on RGB images. This involves estimating the position and orientation of an object in a scene, and is a fundamental problem in computer vision and robotics. In this task, the goal is to estimate the 6D pose of an object given an RGB image of the object and the scene, which can be used for tasks such as robotic manipulation, augmented reality, and scene reconstruction.\n",
      "( Image credit: Segmentation-driven 6D Object Pose Estimation )\n",
      "[241/499]  Action Segmentation is a challenging problem in high-level video understanding. In its simplest form, Action Segmentation aims to segment a temporally untrimmed video by time and label each segmented part with one of pre-defined action labels. The results of Action Segmentation can be further used as input to various applications, such as video-to-text and action localization.\n",
      "Source: TricorNet: A Hybrid Temporal Convolutional and Recurrent Network for Video Action Segmentation\n",
      "[242/499]  Recognising action as a triplet of subject verb and object. Example HOI = Human Object Interaction, Surgical IVT = Instrument Verb Target, etc.\n",
      "[243/499]  The Atari 2600 Games task (and dataset) involves training an agent to achieve high game scores.\n",
      "( Image credit: Playing Atari with Deep Reinforcement Learning )\n",
      "[244/499]  This task has no description! Would you like to contribute one?\n",
      "[245/499]  Brain Tumor Segmentation is a medical image analysis task that involves the separation of brain tumors from normal brain tissue in magnetic resonance imaging (MRI) scans. The goal of brain tumor segmentation is to produce a binary or multi-class segmentation map that accurately reflects the location and extent of the tumor.\n",
      "( Image credit: Brain Tumor Segmentation with Deep Neural Networks )\n",
      "[246/499]  This task has no description! Would you like to contribute one?\n",
      "[247/499]  This task has no description! Would you like to contribute one?\n",
      "[248/499]  This task has no description! Would you like to contribute one?\n",
      "[249/499]  Compressive Sensing is a new signal processing framework for efficiently acquiring and reconstructing a signal that have a sparse representation in a fixed linear basis.\n",
      "Source: Sparse Estimation with Generalized Beta Mixture and the Horseshoe Prior\n",
      "[250/499]  Content-Based Image Retrieval is a well studied problem in computer vision, with retrieval problems generally divided into two groups: category-level retrieval and instance-level retrieval. Given a query image of the Sydney Harbour bridge, for instance, category-level retrieval aims to find any bridge in a given dataset of images, whilst instance-level retrieval must find the Sydney Harbour bridge to be considered a match.\n",
      "Source: Camera Obscurer: Generative Art for Design Inspiration\n",
      "[251/499]  Coreference resolution is the task of clustering mentions in text that refer to the same underlying real world entities.\n",
      "Example:\n",
      "               +-----------+\n",
      "               |           |\n",
      "I voted for Obama because he was most aligned with my values\", she said.\n",
      " |                                                 |            |\n",
      " +-------------------------------------------------+------------+\n",
      "\"I\", \"my\", and \"she\" belong to the same cluster and \"Obama\" and \"he\" belong to the same cluster.\n",
      "[252/499]  For automatic detection of surface defects in various products\n",
      "[253/499]  Dimensionality Reduction methods transform data from a high-dimensional space into a low-dimensional space so that the low-dimensional space retains the most important properties of the original data. Below you can find a continuously updating list of dimensionality reduction methods.\n",
      "[254/499]  Edge Detection is a fundamental image processing technique which involves computing an image gradient to quantify the magnitude and direction of edges in an image. Image gradients are used in various downstream tasks in computer vision such as line detection, feature detection, and image classification.\n",
      "Source: Artistic Enhancement and Style Transfer of Image Edges using Directional Pseudo-coloring\n",
      "( Image credit: Kornia )\n",
      "[255/499]  Assigning a unique identity to entities (such as famous individuals, locations, or companies) mentioned in text (Source: Wikipedia).\n",
      "[256/499]  This task has no description! Would you like to contribute one?\n",
      "[257/499]  Face identification is the task of matching a given face image to one in an existing database of faces. It is the second part of face recognition (the first part being detection). It is a one-to-many mapping: you have to find an unknown person in a database to find who that person is.\n",
      "[258/499]  Classify pixels of a face image into different classes based on a given bounding box.\n",
      "[259/499]  This task has no description! Would you like to contribute one?\n",
      "[260/499]  Facial action unit detection is the task of detecting action units from a video of a face - for example, lip tightening and cheek raising.\n",
      "( Image credit: Self-supervised Representation Learning from Videos for Facial Action Unit Detection )\n",
      "[261/499]  This task has no description! Would you like to contribute one?\n",
      "[262/499]  This task has no description! Would you like to contribute one?\n",
      "[263/499]  Graph Classification is a task that involves classifying a graph-structured data into different classes or categories. Graphs are a powerful way to represent relationships and interactions between different entities, and graph classification can be applied to a wide range of applications, such as social network analysis, bioinformatics, and recommendation systems. In graph classification, the input is a graph, and the goal is to learn a classifier that can accurately predict the class of the graph.\n",
      "( Image credit: Hierarchical Graph Pooling with Structure Learning )\n",
      "[264/499]  This task has no description! Would you like to contribute one?\n",
      "[265/499]  This task has no description! Would you like to contribute one?\n",
      "[266/499]  This task has no description! Would you like to contribute one?\n",
      "[267/499]  This task has no description! Would you like to contribute one?\n",
      "[268/499]  This task has no description! Would you like to contribute one?\n",
      "[269/499]  Image Stitching is a process of composing multiple images with narrow but overlapping fields of view to create a larger image with a wider field of view.\n",
      "Source: Single-Perspective Warps in Natural Image Stitching\n",
      "( Image credit: Kornia )\n",
      "[270/499]  This task has no description! Would you like to contribute one?\n",
      "[271/499]  Imitation Learning is a framework for learning a behavior policy from demonstrations. Usually, demonstrations are presented in the form of state-action trajectories, with each pair indicating the action to take at the state being visited. In order to learn the behavior policy, the demonstrated actions are usually utilized in two ways. The first, known as Behavior Cloning (BC), treats the action as the target label for each state, and then learns a generalized mapping from states to actions in a supervised manner. Another way, known as Inverse Reinforcement Learning (IRL), views the demonstrated actions as a sequence of decisions, and aims at finding a reward/cost function under which the demonstrated decisions are optimal.\n",
      "Finally, a newer methodology, Inverse Q-Learning aims at directly learning Q-functions from expert data, implicitly representing rewards, under which the optimal policy can be given as a Boltzmann distribution similar to soft Q-learning\n",
      "Source: Learning to Imitate\n",
      "[272/499]  This task has no description! Would you like to contribute one?\n",
      "[273/499]  Correction of visual artifacts caused by JPEG compression, these artifacts are usually grouped into three types: blocking, blurring, and ringing. They are caused by quantization and removal of high frequency DCT coefficients.\n",
      "[274/499]  A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel. Source: Distilling the Knowledge in a Neural Network\n",
      "Source:\n",
      "Distilling the Knowledge in a Neural Network\n",
      "Read Paper\n",
      "See Code\n",
      "[275/499]  Learning fine-grained representation with coarsely-labelled dataset, which can significantly reduce the labelling cost. As a simple example, for the task of differentiation between different pets, we need a knowledgeable cat lover to distinguish between ‘British short’ and ‘Siamese’, but even a child annotator may help to discriminate between ‘cat’ and ‘non-cat’.\n",
      "[276/499]  This task has no description! Would you like to contribute one?\n",
      "[277/499]  In its most basic form, MRI reconstruction consists in retrieving a complex-valued image from its under-sampled Fourier coefficients. Besides, it can be addressed as a encoder-decoder task, in which the normative model in the latent space will only capture the relevant information without noise or corruptions. Then, we decode the latent space in order to have a reconstructed MRI.\n",
      "[278/499]  Medical image generation is the task of synthesising new medical images.\n",
      "( Image credit: Towards Adversarial Retinal Image Synthesis )\n",
      "[279/499]  This task has no description! Would you like to contribute one?\n",
      "[280/499]  This task has no description! Would you like to contribute one?\n",
      "[281/499]  This task targets at 3D human pose estimation with a single RGB camera.\n",
      "[282/499]  This task has no description! Would you like to contribute one?\n",
      "[283/499]  Motion forecasting is the task of predicting the location of a tracked object in the future\n",
      "[284/499]  This task has no description! Would you like to contribute one?\n",
      "[285/499]  This task has no description! Would you like to contribute one?\n",
      "[286/499]  This task has no description! Would you like to contribute one?\n",
      "[287/499]  Natural Language Understanding is an important field of Natural Language Processing which contains various tasks such as text classification, natural language inference and story comprehension. Applications enabled by natural language understanding range from question answering to automated reasoning.\n",
      "Source: Find a Reasonable Ending for Stories: Does Logic Relation Help the Story Cloze Test?\n",
      "[288/499]  Network Pruning is a popular approach to reduce a heavy network to obtain a light-weight form by removing redundancy in the heavy network. In this approach, a complex over-parameterized network is first trained, then pruned based on come criterions, and finally fine-tuned to achieve comparable performance with reduced parameters.\n",
      "Source: Ensemble Knowledge Distillation for Learning Improved and Efficient Networks\n",
      "[289/499]  Object Detection in Aerial Images is the task of detecting objects from aerial images.\n",
      "( Image credit: DOTA: A Large-Scale Dataset for Object Detection in Aerial Images )\n",
      "[290/499]  Open-vocabulary detection (OVD) aims to generalize beyond the limited number of base classes labeled during the training phase. The goal is to detect novel classes defined by an unbounded (open) vocabulary at inference.\n",
      "[291/499]  Open World Object Detection is a computer vision problem where a model is tasked to: 1) identify objects that have not been introduced to it as `unknown', without explicit supervision to do so, and 2) incrementally learn these identified unknown categories without forgetting previously learned classes, when the corresponding labels are progressively received.\n",
      "[292/499]  Pedestrian attribution recognition is the task of recognising pedestrian features - such as whether they are talking on a phone, whether they have a backpack, and so on.\n",
      "( Image credit: HydraPlus-Net: Attentive Deep Features for Pedestrian Analysis )\n",
      "[293/499]  This task has no description! Would you like to contribute one?\n",
      "[294/499]  \n",
      "[295/499]  This task has no description! Would you like to contribute one?\n",
      "[296/499]  The task aims at labeling the pixels of an image or video that represent an object instance referred by a linguistic expression. In particular, the referring expression (RE) must allow the identification of an individual object in a discourse or scene (the referent). REs unambiguously identify the target instance.\n",
      "[297/499]  \n",
      "[298/499]  This task is composed of using Deep Learning to identify how best to grasp objects using robotic arms in different scenarios. This is a very complex task as it might involve dynamic environments and objects unknown to the network.\n",
      "[299/499]  This task has no description! Would you like to contribute one?\n",
      "[300/499]  A saliency map is a model that predicts eye fixations on a visual scene.\n",
      "[301/499]  A scene graph is a structured representation of an image, where nodes in a scene graph correspond to object bounding boxes with their object categories, and edges correspond to their pairwise relationships between objects. The task of Scene Graph Generation is to generate a visually-grounded scene graph that most accurately correlates with an image.\n",
      "Source: Scene Graph Generation by Iterative Message Passing\n",
      "[302/499]  Scene parsing is to segment and parse an image into different image regions associated with semantic categories, such as sky, road, person, and bed. MIT Description\n",
      "[303/499]  Scene segmentation is the task of splitting a scene into its various object components.\n",
      "Image adapted from Temporally coherent 4D reconstruction of complex dynamic scenes.\n",
      "[304/499]  The semi-supervised scenario assumes the user inputs a full mask of the object(s) of interest in the first frame of a video sequence. Methods have to produce the segmentation mask for that object(s) in the subsequent frames.\n",
      "[305/499]  Sentiment Analysis is the task of classifying the polarity of a given text. For instance, a text-based tweet can be categorized into either \"positive\", \"negative\", or \"neutral\". Given the text and accompanying labels, a model can be trained to predict the correct sentiment.\n",
      "Sentiment Analysis techniques can be categorized into machine learning approaches, lexicon-based approaches, and even hybrid methods. Some subcategories of research in sentiment analysis include: multimodal sentiment analysis, aspect-based sentiment analysis, fine-grained opinion analysis, language specific sentiment analysis.\n",
      "More recently, deep learning techniques, such as RoBERTa and T5, are used to train high-performing sentiment classifiers that are evaluated using metrics like F1, recall, and precision. To evaluate sentiment analysis systems, benchmark datasets like SST, GLUE, and IMDB movie reviews are used.\n",
      "Further readings:\n",
      "Sentiment Analysis Based on Deep Learning: A Comparative Study\n",
      "[306/499]  This task has no description! Would you like to contribute one?\n",
      "[307/499]  This task has no description! Would you like to contribute one?\n",
      "[308/499]  This task has no description! Would you like to contribute one?\n",
      "[309/499]  This task has no description! Would you like to contribute one?\n",
      "[310/499]  This task has no description! Would you like to contribute one?\n",
      "[311/499]  This task has no description! Would you like to contribute one?\n",
      "[312/499]  This task has no description! Would you like to contribute one?\n",
      "[313/499]  This task has no description! Would you like to contribute one?\n",
      "[314/499]  Image credit: ClevrTex: A Texture-Rich Benchmark for Unsupervised Multi-Object Segmentation\n",
      "[315/499]  Source:\n",
      "Autoencoding Variational Autoencoder\n",
      "Read Paper\n",
      "See Code\n",
      "[316/499]  Video Classification is the task of producing a label that is relevant to the video given its frames. A good video level classifier is one that not only provides accurate frame labels, but also best describes the entire video given the features and the annotations of the various frames in the video. For example, a video might contain a tree in some frame, but the label that is central to the video might be something else (e.g., “hiking”). The granularity of the labels that are needed to describe the frames and the video depends on the task. Typical tasks include assigning one or more global labels to the video, and assigning one or more labels for each frame inside the video.\n",
      "Source: Efficient Large Scale Video Classification\n",
      "[317/499]  The objective of video retrieval is as follows: given a text query and a pool of candidate videos, select the video which corresponds to the text query. Typically, the videos are returned as a ranked list of candidates and scored via document retrieval metrics.\n",
      "[318/499]  This task has no description! Would you like to contribute one?\n",
      "[319/499]  Video Super-Resolution is a computer vision task that aims to increase the resolution of a video sequence, typically from lower to higher resolutions. The goal is to generate high-resolution video frames from low-resolution input, improving the overall quality of the video.\n",
      "( Image credit: Detail-revealing Deep Video Super-Resolution )\n",
      "[320/499]  This task has no description! Would you like to contribute one?\n",
      "[321/499]  Visual relationship detection (VRD) is one newly developed computer vision task aiming to recognize relations or interactions between objects in an image. It is a further learning task after object recognition and is essential for fully understanding images, even the visual world.\n",
      "[322/499]  This task has no description! Would you like to contribute one?\n",
      "[323/499]  3D facial expression recognition is the task of modelling facial expressions in 3D from an image or video.\n",
      "( Image credit: Expression-Net )\n",
      "[324/499]  This task has no description! Would you like to contribute one?\n",
      "[325/499]  This task aims to solve root-relative 3D multi-person pose estimation. No human bounding box and root joint coordinate groundtruth are used in testing time.\n",
      "( Image credit: RootNet )\n",
      "[326/499]  Image: Choy et al\n",
      "[327/499]  Encoding and reconstruction of 3D point clouds.\n",
      "[328/499]  Abnormal Event Detection In Video is a challenging task in computer vision, as the definition of what an abnormal event looks like depends very much on the context. For instance, a car driving by on the street is regarded as a normal event, but if the car enters a pedestrian area, this is regarded as an abnormal event. A person running on a sports court (normal event) versus running outside from a bank (abnormal event) is another example. Although what is considered abnormal depends on the context, we can generally agree that abnormal events should be unexpected events that occur less often than familiar (normal) events\n",
      "Source: Unmasking the abnormal events in video\n",
      "Image: Ravanbakhsh et al\n",
      "[329/499]  This task has no description! Would you like to contribute one?\n",
      "[330/499]  Action Recognition in Videos is a task in computer vision and pattern recognition where the goal is to identify and categorize human actions performed in a video sequence. The task involves analyzing the spatiotemporal dynamics of the actions and mapping them to a predefined set of action classes, such as running, jumping, or swimming.\n",
      "[331/499]  Action unit detection is the task of detecting action units from a video - for example, types of facial action units (lip tightening, cheek raising) from a video of a face.\n",
      "( Image credit: AU R-CNN )\n",
      "[332/499]  Age and gender classification is a dual-task of identifying the age and gender of a person from an image or video.\n",
      "( Image credit: Multi-Expert Gender Classification on Age Group by Integrating Deep Neural Networks )\n",
      "[333/499]  Age-invariant face recognition is the task of performing face recognition that is invariant to differences in age.\n",
      "( Image credit: Look Across Elapse )\n",
      "[334/499]  Blended-target domain adaptation is to adapt a single source model to multiple different target domains. The task is similar to the multi-target domain adaptation. However, the domain labels are not available.\n",
      "[335/499]  Blind face restoration aims at recovering high-quality faces from the low-quality counterparts suffering from unknown degradation, such as low-resolution, noise, blur, compression artifacts, etc. When applied to real-world scenarios, it becomes more challenging, due to more complicated degradation, diverse poses and expressions.\n",
      "Description source: Towards Real-World Blind Face Restoration with Generative Facial Prior\n",
      "Image source: Towards Real-World Blind Face Restoration with Generative Facial Prior\n",
      "[336/499]  Detection of the persons or the characters defined in the dataset.\n",
      "[337/499]  Boundary Detection is a vital part of extracting information encoded in images, allowing for the computation of quantities of interest including density, velocity, pressure, etc.\n",
      "Source: A Locally Adapting Technique for Boundary Detection using Image Segmentation\n",
      "[338/499]  This task has no description! Would you like to contribute one?\n",
      "[339/499]  This task has no description! Would you like to contribute one?\n",
      "[340/499]  Change Detection is a computer vision task that involves detecting changes in an image or video sequence over time. The goal is to identify areas in the image or video that have undergone changes, such as appearance changes, object disappearance or appearance, or even changes in the scene's background.\n",
      "Image credit: \"A TRANSFORMER-BASED SIAMESE NETWORK FOR CHANGE DETECTION\"\n",
      "[341/499]  Question Answering task on charts images\n",
      "[342/499]  This task has no description! Would you like to contribute one?\n",
      "[343/499]  The majority of all optical observations collected via spaceborne satellites are affected by haze or clouds. Consequently, persistent cloud coverage affects the remote sensing practitioner's capabilities of a continuous and seamless monitoring of our planet. Cloud removal is the task of reconstructing cloud-covered information while preserving originally cloud-free details.\n",
      "Image Source: URL\n",
      "[344/499]  This task has no description! Would you like to contribute one?\n",
      "[345/499]  Color Constancy is the ability of the human vision system to perceive the colors of the objects in the scene largely invariant to the color of the light source. The task of computational Color Constancy is to estimate the scene illumination and then perform the chromatic adaptation in order to remove the influence of the illumination color on the colors of the objects in the scene.\n",
      "Source: CroP: Color Constancy Benchmark Dataset Generator\n",
      "[346/499]  This task has no description! Would you like to contribute one?\n",
      "[347/499]  \n",
      "[348/499]  This task has no description! Would you like to contribute one?\n",
      "[349/499]  This task has no description! Would you like to contribute one?\n",
      "[350/499]  This task has no description! Would you like to contribute one?\n",
      "[351/499]  This task has no description! Would you like to contribute one?\n",
      "[352/499]  Grading the severity of diabetic retinopathy from (ophthalmic) fundus images\n",
      "[353/499]  Dialogue generation is the task of \"understanding\" natural language inputs - within natural language processing in order to produce output. The systems are usually intended for conversing with humans, for instance back and forth dialogue with a conversation agent like a chatbot. Some example benchmarks for this task (see others such as Natural Language Understanding) include FusedChat and Ubuntu DIalogue Corpus (UDC). Models can be evaluated via metrics such as BLEU, ROUGE, and METEOR albeit with challenges in terms of weak correlation with human judgement, that may be addressed by new ones like UnSupervised and Reference-free (USR) and Metric for automatic Unreferenced dialog evaluation (MaUde).\n",
      "[354/499]  The Disparity Estimation is the task of finding the pixels in the multiscopic views that correspond to the same 3D point in the scene.\n",
      "[355/499]  This task has no description! Would you like to contribute one?\n",
      "[356/499]  Driver attention monitoring is the task of monitoring the attention of a driver.\n",
      "( Image credit: Predicting Driver Attention in Critical Situations )\n",
      "[357/499]  XAI refers to methods and techniques in the application of artificial intelligence (AI) such that the results of the solution can be understood by humans. It contrasts with the concept of the \"black box\" in machine learning where even its designers cannot explain why an AI arrived at a specific decision. XAI may be an implementation of the social right to explanation. XAI is relevant even if there is no legal right or regulatory requirement—for example, XAI can improve the user experience of a product or service by helping end users trust that the AI is making good decisions. This way the aim of XAI is to explain what has been done, what is done right now, what will be done next and unveil the information the actions are based on. These characteristics make it possible (i) to confirm existing knowledge (ii) to challenge existing knowledge and (iii) to generate new assumptions.\n",
      "[358/499]  Face generation is the task of generating (or interpolating) new faces from an existing dataset.\n",
      "The state-of-the-art results for this task are located in the Image Generation parent.\n",
      "( Image credit: Progressive Growing of GANs for Improved Quality, Stability, and Variation )\n",
      "[359/499]  Face hallucination is the task of generating high-resolution (HR) facial images from low-resolution (LR) inputs.\n",
      "( Image credit: Deep CNN Denoiser and Multi-layer Neighbor Component Embedding for Face Hallucination )\n",
      "[360/499]  This task has no description! Would you like to contribute one?\n",
      "[361/499]  Emotion Recognition from facial images\n",
      "[362/499]  Facial inpainting (or face completion) is the task of generating plausible facial structures for missing pixels in a face image.\n",
      "( Image credit: SymmFCNet )\n",
      "[363/499]  Fake News Detection is a natural language processing task that involves identifying and classifying news articles or other types of text as real or fake. The goal of fake news detection is to develop algorithms that can automatically identify and flag fake news articles, which can be used to combat misinformation and promote the dissemination of accurate information.\n",
      "[364/499]  This task has no description! Would you like to contribute one?\n",
      "[365/499]  Few-shot semantic segmentation (FSS) learns to segment target objects in query image given few pixel-wise annotated support image.\n",
      "[366/499]  This task has no description! Would you like to contribute one?\n",
      "[367/499]  This task has no description! Would you like to contribute one?\n",
      "[368/499]  This task has no description! Would you like to contribute one?\n",
      "[369/499]  This task has no description! Would you like to contribute one?\n",
      "[370/499]  Predict contact between object and hand (human or robot).\n",
      "[371/499]  This task has no description! Would you like to contribute one?\n",
      "[372/499]  This task has no description! Would you like to contribute one?\n",
      "[373/499]  The goal of handwriting verification is to find a measure of confidence whether the given handwritten samples are written by the same or different writer.\n",
      "[374/499]  This task has no description! Would you like to contribute one?\n",
      "[375/499]  Yan et al. (2019) CSGN:\n",
      "\"When the dancer is stepping, jumping and spinning on the stage, attentions of all audiences are attracted by the streamof the fluent and graceful movements. Building a model that is capable of dancing is as fascinating a task as appreciating the performance itself. In this paper, we aim to generate long-duration human actions represented as skeleton sequences, e.g. those that cover the entirety of a dance, with hundreds of moves and countless possible combinations.\"\n",
      "( Image credit: Convolutional Sequence Generation for Skeleton-Based Action Synthesis )\n",
      "[376/499]  Image Cropping is a common photo manipulation process, which improves the overall composition by removing unwanted regions. Image Cropping is widely used in photographic, film processing, graphic design, and printing businesses.\n",
      "Source: Listwise View Ranking for Image Cropping\n",
      "[377/499]  This task has no description! Would you like to contribute one?\n",
      "[378/499]  This task has no description! Would you like to contribute one?\n",
      "[379/499]  This task has no description! Would you like to contribute one?\n",
      "[380/499]  Layout-to-image generation its the task to generate a scene based on the given layout. The layout describes the location of the objects to be included in the output image. In this section, you can find state-of-the-art leaderboards for Layout-to-image generation.\n",
      "[381/499]  This task has no description! Would you like to contribute one?\n",
      "[382/499]  Machine translation is the task of translating a sentence in a source language to a different target language.\n",
      "Approaches for machine translation can range from rule-based to statistical to neural-based. More recently, encoder-decoder attention-based architectures like BERT have attained major improvements in machine translation.\n",
      "One of the most popular datasets used to benchmark machine translation systems is the WMT family of datasets. Some of the most commonly used evaluation metrics for machine translation systems include BLEU, METEOR, NIST, and others.\n",
      "( Image credit: Google seq2seq )\n",
      "[383/499]  This task has no description! Would you like to contribute one?\n",
      "[384/499]  Medical Image Classification is a task in medical image analysis that involves classifying medical images, such as X-rays, MRI scans, and CT scans, into different categories based on the type of image or the presence of specific structures or diseases. The goal is to use computer algorithms to automatically identify and classify medical images based on their content, which can help in diagnosis, treatment planning, and disease monitoring.\n",
      "[385/499]  Image registration, also known as image fusion or image matching, is the process of aligning two or more images based on image appearances. Medical Image Registration seeks to find an optimal spatial transformation that best aligns the underlying anatomical structures. Medical Image Registration is used in many clinical applications such as image guidance, motion tracking, segmentation, dose accumulation, image reconstruction and so on. Medical Image Registration is a broad topic which can be grouped from various perspectives. From input image point of view, registration methods can be divided into unimodal, multimodal, interpatient, intra-patient (e.g. same- or different-day) registration. From deformation model point of view, registration methods can be divided in to rigid, affine and deformable methods. From region of interest (ROI) perspective, registration methods can be grouped according to anatomical sites such as brain, lung registration and so on. From image pair dimension perspective, registration methods can be divided into 3D to 3D, 3D to 2D and 2D to 2D/3D.\n",
      "Source: Deep Learning in Medical Image Registration: A Review\n",
      "[386/499]  Meme classification refers to the task of classifying internet memes.\n",
      "[387/499]  Facial Micro-Expression Recognition is a challenging task in identifying suppressed emotion in a high-stake environment, often comes in very brief duration and subtle changes.\n",
      "[388/499]  This task has no description! Would you like to contribute one?\n",
      "[389/499]  Monocular 3D Object Detection is the task to draw 3D bounding box around objects in a single 2D RGB image. It is localization task but without any extra information like depth or other sensors or multiple-images.\n",
      "[390/499]  Motion Estimation is used to determine the block-wise or pixel-wise motion vectors between two frames.\n",
      "Source: MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement\n",
      "[391/499]  Multi-human parsing is the task of parsing multiple humans in crowded scenes.\n",
      "( Image credit: Multi-Human Parsing )\n",
      "[392/499]  This task has no description! Would you like to contribute one?\n",
      "[393/499]  This task has no description! Would you like to contribute one?\n",
      "[394/499]  The idea of Multi-target Domain Adaptation is to adapt a model from a single labelled source domain to multiple unlabelled target domains.\n",
      "[395/499]  This task has no description! Would you like to contribute one?\n",
      "[396/499]  Multimodal sentiment analysis is the task of performing sentiment analysis with multiple data sources - e.g. a camera feed of someone's face and their recorded speech.\n",
      "( Image credit: ICON: Interactive Conversational Memory Network for Multimodal Emotion Detection )\n",
      "[397/499]  Multimodal unsupervised image-to-image translation is the task of producing multiple translations to one domain from a single image in another domain.\n",
      "( Image credit: MUNIT: Multimodal UNsupervised Image-to-image Translation )\n",
      "[398/499]  Incorporating multiple camera views for detection in heavily occluded scenarios.\n",
      "[399/499]  Named Entity Recognition (NER) is a task of Natural Language Processing (NLP) that involves identifying and classifying named entities in a text into predefined categories such as person names, organizations, locations, and others. The goal of NER is to extract structured information from unstructured text data and represent it in a machine-readable format. Approaches typically use BIO notation, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens.\n",
      "Example:\n",
      "Mark Watney visited Mars\n",
      "B-PER I-PER O B-LOC\n",
      "( Image credit: Zalando )\n",
      "[400/499]  Given a representation of a 3D scene of some kind (point cloud, mesh, voxels, etc.), the task is to create an algorithm that can produce photorealistic renderings of this scene from an arbitrary viewpoint. Sometimes, the task is accompanied by image/scene appearance manipulation.\n",
      "[401/499]  The goal of Novel Class Discovery (NCD) is to identify new classes in unlabeled data, by exploiting prior knowledge from known classes. In this specific setup, the data is split in two sets. The first is a labeled set containing known classes and the second is an unlabeled set containing unknown classes that must be discovered.\n",
      "[402/499]  One-shot learning is the task of learning information about object categories from a single training example.\n",
      "( Image credit: Siamese Neural Networks for One-shot Image Recognition )\n",
      "[403/499]  ( Image credit: Siamese Mask R-CNN )\n",
      "[404/499]  This task has no description! Would you like to contribute one?\n",
      "[405/499]  The goal of Online Multi-Object Tracking is to estimate the spatio-temporal trajectories of multiple objects in an online video stream (i.e., the video is provided frame-by-frame), which is a fundamental problem for numerous real-time applications, such as video surveillance, autonomous driving, and robot navigation.\n",
      "Source: A Hybrid Data Association Framework for Robust Online Multi-Object Tracking\n",
      "[406/499]  This task has no description! Would you like to contribute one?\n",
      "[407/499]  Region proposal for optic disc\n",
      "[408/499]  This task has no description! Would you like to contribute one?\n",
      "[409/499]  This task has no description! Would you like to contribute one?\n",
      "[410/499]  This task has no description! Would you like to contribute one?\n",
      "[411/499]  Pose Tracking is the task of estimating multi-person human poses in videos and assigning unique instance IDs for each keypoint across frames. Accurate estimation of human keypoint-trajectories is useful for human action recognition, human interaction understanding, motion capture and animation.\n",
      "Source: LightTrack: A Generic Framework for Online Top-Down Human Pose Tracking\n",
      "[412/499]  This task has no description! Would you like to contribute one?\n",
      "[413/499]  This task has no description! Would you like to contribute one?\n",
      "[414/499]  This task has no description! Would you like to contribute one?\n",
      "[415/499]  Similar to its parent task, instance segmentation, but with the goal of achieving real-time capabilities under a defined setting.\n",
      "Image Credit: SipMask: Spatial Information Preservation for Fast Image and Video Instance Segmentation\n",
      "[416/499]  \n",
      "[417/499]  Relation Extraction is the task of predicting attributes and relations for entities in a sentence. For example, given a sentence “Barack Obama was born in Honolulu, Hawaii.”, a relation classifier aims at predicting the relation of “bornInCity”. Relation Extraction is the key component for building relation knowledge graphs, and it is of crucial significance to natural language processing applications such as structured search, sentiment analysis, question answering, and summarization.\n",
      "Source: Deep Residual Learning for Weakly-Supervised Relation Extraction\n",
      "[418/499]  This task has no description! Would you like to contribute one?\n",
      "[419/499]  Robust face recognition is the task of performing recognition in an unconstrained environment, where there is variation of view-point, scale, pose, illumination and expression of the face images.\n",
      "( Image credit: MeGlass dataset )\n",
      "[420/499]  This task has no description! Would you like to contribute one?\n",
      "[421/499]  Satellite image classification is the most significant technique used in remote sensing for the computerized study and pattern recognition of satellite information, which is based on diversity structures of the image that involve rigorous validation of the training samples depending on the used classification algorithm.\n",
      "[422/499]  Scene Flow Estimation is the task of obtaining 3D structure and 3D motion of dynamic scenes, which is crucial to environment perception, e.g., in the context of autonomous navigation.\n",
      "Source: Self-Supervised Monocular Scene Flow Estimation\n",
      "[423/499]  This task has no description! Would you like to contribute one?\n",
      "[424/499]  This task has no description! Would you like to contribute one?\n",
      "[425/499]  SLAM with semantic level scene understanding\n",
      "[426/499]  The task of semantic correspondence aims to establish reliable visual correspondence between different instances of the same object category.\n",
      "[427/499]  This task has no description! Would you like to contribute one?\n",
      "[428/499]  Models that are trained with a small number of labeled examples and a large number of unlabeled examples and whose aim is to learn to segment an image (i.e. assign a class to every pixel).\n",
      "[429/499]  This task has no description! Would you like to contribute one?\n",
      "[430/499]  This task has no description! Would you like to contribute one?\n",
      "[431/499]  This task has no description! Would you like to contribute one?\n",
      "[432/499]  This task has no description! Would you like to contribute one?\n",
      "[433/499]  Small Object Detection is a computer vision task that involves detecting and localizing small objects in images or videos. This task is challenging due to the small size and low resolution of the objects, as well as other factors such as occlusion, background clutter, and variations in lighting conditions.\n",
      "( Image credit: Feature-Fused SSD )\n",
      "[434/499]  This task has no description! Would you like to contribute one?\n",
      "[435/499]  This task has no description! Would you like to contribute one?\n",
      "[436/499]  This task has no description! Would you like to contribute one?\n",
      "[437/499]  Synthetic-to-real translation is the task of domain adaptation from synthetic (or virtual) data to real data.\n",
      "( Image credit: CYCADA )\n",
      "[438/499]  This task has no description! Would you like to contribute one?\n",
      "[439/499]  This task has no description! Would you like to contribute one?\n",
      "[440/499]  Time series analysis comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data.\n",
      "[441/499]  Time Series Classification is a general task that can be useful across many subject-matter domains and applications. The overall goal is to identify a time series as coming from one of possibly many sources or predefined groups, using labeled training data. That is, in this setting we conduct supervised learning, where the different time series sources are considered known.\n",
      "Source: Nonlinear Time Series Classification Using Bispectrum-based Deep Convolutional Neural Networks\n",
      "[442/499]  This task has no description! Would you like to contribute one?\n",
      "[443/499]  Traffic sign recognition is the task of recognising traffic signs in an image or video.\n",
      "( Image credit: Novel Deep Learning Model for Traffic Sign Detection Using Capsule Networks )\n",
      "[444/499]  Trajectory forecasting is a sequential prediction task, where a forecasting model predicts future trajectories of all moving agents (humans, vehicles, etc.) in a scene, based on their past trajectories and/or the scene context.\n",
      "(Illustrative figure from Social NCE: Contrastive Learning of Socially-aware Motion Representations)\n",
      "[445/499]  This task has no description! Would you like to contribute one?\n",
      "[446/499]  This task has no description! Would you like to contribute one?\n",
      "[447/499]  Facial landmark detection in the unsupervised setting popularized by [1]. The evaluation occurs in two stages: (1) Embeddings are first learned in an unsupervised manner (i.e. without labels); (2) A simple regressor is trained to regress landmarks from the unsupervised embedding.\n",
      "[1] Thewlis, James, Hakan Bilen, and Andrea Vedaldi. \"Unsupervised learning of object landmarks by factorized spatial embeddings.\" Proceedings of the IEEE International Conference on Computer Vision. 2017.\n",
      "( Image credit: Unsupervised learning of object landmarks by factorized spatial embeddings )\n",
      "[448/499]  This task has no description! Would you like to contribute one?\n",
      "[449/499]  This task has no description! Would you like to contribute one?\n",
      "[450/499]  Pre-training a neural network using unsupervised (self-supervised) auxiliary tasks on unlabeled data.\n",
      "[451/499]  This task has no description! Would you like to contribute one?\n",
      "[452/499]  \n",
      "[453/499]  ( Various Video Generation Tasks. Gif credit: MaGViT )\n",
      "[454/499]  Video Object Detection aims to detect targets in videos using both spatial and temporal information. It's usually deeply integrated with tasks such as Object Detection and Object Tracking.\n",
      "[455/499]  Video salient object detection (VSOD) is significantly essential for understanding the underlying mechanism behind HVS during free-viewing in general and instrumental to a wide range of real-world applications, e.g., video segmentation, video captioning, video compression, autonomous driving, robotic interaction, weakly supervised attention. Besides its academic value and practical significance, VSOD presents great difficulties due to the challenges carried by video data (diverse motion patterns, occlusions, blur, large object deformations, etc.) and the inherent complexity of human visual attention behavior (i.e., selective attention allocation, attention shift) during dynamic scenes. Online benchmark: http://dpfan.net/davsod.\n",
      "( Image credit: Shifting More Attention to Video Salient Object Detection, CVPR2019-Best Paper Finalist )\n",
      "[456/499]  Video Summarization aims to generate a short synopsis that summarizes the video content by selecting its most informative and important parts. The produced summary is usually composed of a set of representative video frames (a.k.a. video key-frames), or video fragments (a.k.a. video key-fragments) that have been stitched in chronological order to form a shorter video. The former type of a video summary is known as video storyboard, and the latter type is known as video skim.\n",
      "Source: Video Summarization Using Deep Neural Networks: A Survey\n",
      "Image credit: iJRASET\n",
      "[457/499]  Video-based person re-identification (reID) aims to retrieve person videos with the same identity as a query person across multiple cameras\n",
      "[458/499]  Visual Grounding (VG) aims to locate the most relevant object or region in an image, based on a natural language query. The query can be a phrase, a sentence, or even a multi-round dialogue. There are three main challenges in VG:\n",
      "What is the main focus in a query?\n",
      "How to understand an image?\n",
      "How to locate an object?\n",
      "[459/499]  This task has no description! Would you like to contribute one?\n",
      "[460/499]  This task has no description! Would you like to contribute one?\n",
      "[461/499]  The semantic segmentation task is to assign a label from a label set to each pixel in an image. In the case of fully supervised setting, the dataset consists of images and their corresponding pixel-level class-specific annotations (expensive pixel-level annotations). However, in the weakly-supervised setting, the dataset consists of images and corresponding annotations that are relatively easy to obtain, such as tags/labels of objects present in the image.\n",
      "( Image credit: Weakly-Supervised Semantic Segmentation Network with Deep Seeded Region Growing )\n",
      "[462/499]  Zero-Shot Cross-Modal Retrieval is the task of finding relevant items across different modalities without having received any training examples. For example, given an image, find a text or vice versa. The main challenge in the task is known as the heterogeneity gap: since items from different modalities have different data types, the similarity between them cannot be measured directly. Therefore, the majority of methods published to date attempt to bridge this gap by learning a latent representation space, where the similarity between items from different modalities can be measured.\n",
      "Source: Scene-centric vs. Object-centric Image-Text Cross-modal Retrieval: A Reproducibility Study\n",
      "[463/499]  This task has no description! Would you like to contribute one?\n",
      "[464/499]  This task has no description! Would you like to contribute one?\n",
      "[465/499]  This task has no description! Would you like to contribute one?\n",
      "[466/499]  This task has no description! Would you like to contribute one?\n",
      "[467/499]  3D-only Anomaly Detection\n",
      "[468/499]  This task has no description! Would you like to contribute one?\n",
      "[469/499]  Image: Zhang et al\n",
      "[470/499]  This task has no description! Would you like to contribute one?\n",
      "[471/499]  Image: Weng et al\n",
      "[472/499]  This task has no description! Would you like to contribute one?\n",
      "[473/499]  This task aims to solve absolute 3D multi-person pose Estimation (camera-centric coordinates). No ground truth human bounding box and human root joint coordinates are used during testing stage.\n",
      "( Image credit: RootNet )\n",
      "[474/499]  Estimating oriented 3D bounding boxes from Stereo Cameras only.\n",
      "Image: You et al\n",
      "[475/499]  Image: Zou et al\n",
      "[476/499]  This task has no description! Would you like to contribute one?\n",
      "[477/499]  Image: Zeng et al\n",
      "[478/499]  Image source: The Kinetics Human Action Video Dataset\n",
      "[479/499]  This task has no description! Would you like to contribute one?\n",
      "[480/499]  Detecting activities in extended videos.\n",
      "[481/499]  An Adversarial Attack is a technique to find a perturbation that changes the prediction of a machine learning model. The perturbation can be very small and imperceptible to human eyes.\n",
      "Source: Recurrent Attention Model with Log-Polar Mapping is Robust against Adversarial Attacks\n",
      "[482/499]  Automatic assessment of aesthetic-related subjective ratings.\n",
      "[483/499]  Affordance detection refers to identifying the potential action possibilities of objects in an image, which is an important ability for robot perception and manipulation.\n",
      "Image source: Object-Based Affordances Detection with Convolutional Neural Networks and Dense Conditional Random Fields\n",
      "Unlike other visual or physical properties that mainly describe the object alone, affordances indicate functional interactions of object parts with humans.\n",
      "[484/499]  Autonomous navigation is the task of autonomously navigating a vehicle or robot to or around a location without human guidance.\n",
      "( Image credit: Approximate LSTMs for Time-Constrained Inference: Enabling Fast Reaction in Self-Driving Cars )\n",
      "[485/499]  Bias detection is the task of detecting and measuring racism, sexism and otherwise discriminatory behavior in a model (Source: https://stereoset.mit.edu/)\n",
      "[486/499]  This task has no description! Would you like to contribute one?\n",
      "[487/499]  This task aims to achieve instance segmentation with weakly bounding box annotations.\n",
      "[488/499]  ( Image credit: 3D fully convolutional networks for subcortical segmentation in MRI: A large-scale study )\n",
      "[489/499]  This task has no description! Would you like to contribute one?\n",
      "[490/499]  This task has no description! Would you like to contribute one?\n",
      "[491/499]  \"Camera relocalization, or image-based localization is a fundamental problem in robotics and computer vision. It refers to the process of determining camera pose from the visual scene representation and it is essential for many applications such as navigation of autonomous vehicles, structure from motion (SfM), augmented reality (AR) and simultaneous localization and mapping (SLAM).\" (Source)\n",
      "[492/499]  Camouflaged object segmentation (COS) or Camouflaged object detection (COD), which was originally promoted by T.-N. Le et al. (2017), aims to identify objects that conceal their texture into the surrounding environment. The high intrinsic similarities between the target object and the background make COS/COD far more challenging than the traditional object segmentation task. Also, refer to the online benchmarks on CAMO dataset, COD dataset, and online demo.\n",
      "( Image source: Anabranch Network for Camouflaged Object Segmentation )\n",
      "[493/499]  This task has no description! Would you like to contribute one?\n",
      "[494/499]  Cell Segmentation is a task of splitting a microscopic image domain into segments, which represent individual instances of cells. It is a fundamental step in many biomedical studies, and it is regarded as a cornerstone of image-based cellular research. Cellular morphology is an indicator of a physiological state of the cell, and a well-segmented image can capture biologically relevant morphological information.\n",
      "Source: Cell Segmentation by Combining Marker-controlled Watershed and Deep Learning\n",
      "[495/499]  This task has no description! Would you like to contribute one?\n",
      "[496/499]  This task has no description! Would you like to contribute one?\n",
      "[497/499]  Co-Salient Object Detection is a computational problem that aims at highlighting the common and salient foreground regions (or objects) in an image group. Please also refer to the online benchmark: http://dpfan.net/cosod3k/\n",
      "( Image credit: Taking a Deeper Look at Co-Salient Object Detection, CVPR2020 )\n",
      "[498/499]  A core set in machine learning is defined as the minimal set of training samples that allows a supervised algorithm to deliver a result as good as the one obtained when the whole set is used.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(title_list)):\n",
    "\n",
    "    task_obj = {}\n",
    "    task_obj['task'] = title_list[i]\n",
    "\n",
    "    box = browser.find_element(By.NAME, 'q')\n",
    "    box.send_keys(task_obj['task'])\n",
    "    box.submit()\n",
    "\n",
    "    try:\n",
    "        description = browser.find_element(By.CLASS_NAME, 'description')\n",
    "        task_obj['script'] = description.text\n",
    "        task_obj['url'] = browser.current_url\n",
    "        obj.append(task_obj)\n",
    "        print(f'[{i}/{len(title_list)}]  {description.text}')\n",
    "\n",
    "    except:\n",
    "        error_id = {'len_id': i, 'task': task_obj['task']}\n",
    "        not_page.append(error_id)\n",
    "        box = browser.find_element(By.NAME, 'q')\n",
    "        box.clear()\n",
    "\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>script</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semantic Segmentation</td>\n",
       "      <td>Semantic Segmentation is a computer vision tas...</td>\n",
       "      <td>https://paperswithcode.com/task/semantic-segme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Object Detection</td>\n",
       "      <td>Object Detection is a computer vision task in ...</td>\n",
       "      <td>https://paperswithcode.com/task/object-detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Classification</td>\n",
       "      <td>Image Classification is a fundamental task tha...</td>\n",
       "      <td>https://paperswithcode.com/task/image-classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pose Estimation</td>\n",
       "      <td>Pose Estimation is a computer vision task wher...</td>\n",
       "      <td>https://paperswithcode.com/task/pose-estimation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>Facial Recognition is the task of making a pos...</td>\n",
       "      <td>https://paperswithcode.com/task/face-recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Cell Segmentation</td>\n",
       "      <td>Cell Segmentation is a task of splitting a mic...</td>\n",
       "      <td>https://paperswithcode.com/task/cell-segmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Clean-label Backdoor Attack (0.05%)</td>\n",
       "      <td>This task has no description! Would you like t...</td>\n",
       "      <td>https://paperswithcode.com/task/clean-label-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Clothes Landmark Detection</td>\n",
       "      <td>This task has no description! Would you like t...</td>\n",
       "      <td>https://paperswithcode.com/task/clothes-landma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Co-Salient Object Detection</td>\n",
       "      <td>Co-Salient Object Detection is a computational...</td>\n",
       "      <td>https://paperswithcode.com/task/co-saliency-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Core set discovery</td>\n",
       "      <td>A core set in machine learning is defined as t...</td>\n",
       "      <td>https://paperswithcode.com/task/core-set-disco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    task  \\\n",
       "0                  Semantic Segmentation   \n",
       "1                       Object Detection   \n",
       "2                   Image Classification   \n",
       "3                        Pose Estimation   \n",
       "4                       Face Recognition   \n",
       "..                                   ...   \n",
       "494                    Cell Segmentation   \n",
       "495  Clean-label Backdoor Attack (0.05%)   \n",
       "496           Clothes Landmark Detection   \n",
       "497          Co-Salient Object Detection   \n",
       "498                   Core set discovery   \n",
       "\n",
       "                                                script  \\\n",
       "0    Semantic Segmentation is a computer vision tas...   \n",
       "1    Object Detection is a computer vision task in ...   \n",
       "2    Image Classification is a fundamental task tha...   \n",
       "3    Pose Estimation is a computer vision task wher...   \n",
       "4    Facial Recognition is the task of making a pos...   \n",
       "..                                                 ...   \n",
       "494  Cell Segmentation is a task of splitting a mic...   \n",
       "495  This task has no description! Would you like t...   \n",
       "496  This task has no description! Would you like t...   \n",
       "497  Co-Salient Object Detection is a computational...   \n",
       "498  A core set in machine learning is defined as t...   \n",
       "\n",
       "                                                   url  \n",
       "0    https://paperswithcode.com/task/semantic-segme...  \n",
       "1     https://paperswithcode.com/task/object-detection  \n",
       "2    https://paperswithcode.com/task/image-classifi...  \n",
       "3      https://paperswithcode.com/task/pose-estimation  \n",
       "4     https://paperswithcode.com/task/face-recognition  \n",
       "..                                                 ...  \n",
       "494  https://paperswithcode.com/task/cell-segmentation  \n",
       "495  https://paperswithcode.com/task/clean-label-ba...  \n",
       "496  https://paperswithcode.com/task/clothes-landma...  \n",
       "497  https://paperswithcode.com/task/co-saliency-de...  \n",
       "498  https://paperswithcode.com/task/core-set-disco...  \n",
       "\n",
       "[499 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "descriptions = pd.DataFrame(obj)\n",
    "display(descriptions)\n",
    "descriptions.to_csv('./description.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translator:\n",
    "\n",
    "    def __init__(self):\n",
    "        options = Options()\n",
    "        options.add_argument('--headless')\n",
    "        browser = webdriver.Chrome(options=options)\n",
    "        browser.implicitly_wait(3)\n",
    "        self._browser = browser\n",
    "\n",
    "    def translate(self, text, dest='ja'):\n",
    "        browser = self._browser\n",
    "\n",
    "        # 翻訳したい文をURLに埋め込んでからアクセスする\n",
    "        text_for_url = urllib.parse.quote_plus(text, safe='')\n",
    "        url = \"https://translate.google.co.jp/#en/ja/{0}\".format(text_for_url)\n",
    "        browser.get(url)\n",
    "\n",
    "        # 数秒待機する\n",
    "        wait_time = 2 + len(text) / 100\n",
    "        time.sleep(wait_time)\n",
    "\n",
    "        # 翻訳結果を抽出する\n",
    "        ja = browser.find_element(By.CSS_SELECTOR ,\"span[jsname='W297wb']\")\n",
    "        return ja.text\n",
    "\n",
    "    def quit(self):\n",
    "        self._browser.quit()\n",
    "\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "# ja = translator.translate('machine learning')\n",
    "# print(ja) # => 機械学習\n",
    "\n",
    "# ja = translator.translate('natural language processing')\n",
    "# print(ja) # => 自然言語処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>script</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Semantic Segmentation</td>\n",
       "      <td>Semantic Segmentation is a computer vision tas...</td>\n",
       "      <td>https://paperswithcode.com/task/semantic-segme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Object Detection</td>\n",
       "      <td>Object Detection is a computer vision task in ...</td>\n",
       "      <td>https://paperswithcode.com/task/object-detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Classification</td>\n",
       "      <td>Image Classification is a fundamental task tha...</td>\n",
       "      <td>https://paperswithcode.com/task/image-classifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pose Estimation</td>\n",
       "      <td>Pose Estimation is a computer vision task wher...</td>\n",
       "      <td>https://paperswithcode.com/task/pose-estimation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Face Recognition</td>\n",
       "      <td>Facial Recognition is the task of making a pos...</td>\n",
       "      <td>https://paperswithcode.com/task/face-recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Cell Segmentation</td>\n",
       "      <td>Cell Segmentation is a task of splitting a mic...</td>\n",
       "      <td>https://paperswithcode.com/task/cell-segmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Clean-label Backdoor Attack (0.05%)</td>\n",
       "      <td>This task has no description! Would you like t...</td>\n",
       "      <td>https://paperswithcode.com/task/clean-label-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Clothes Landmark Detection</td>\n",
       "      <td>This task has no description! Would you like t...</td>\n",
       "      <td>https://paperswithcode.com/task/clothes-landma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Co-Salient Object Detection</td>\n",
       "      <td>Co-Salient Object Detection is a computational...</td>\n",
       "      <td>https://paperswithcode.com/task/co-saliency-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Core set discovery</td>\n",
       "      <td>A core set in machine learning is defined as t...</td>\n",
       "      <td>https://paperswithcode.com/task/core-set-disco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    task  \\\n",
       "0                  Semantic Segmentation   \n",
       "1                       Object Detection   \n",
       "2                   Image Classification   \n",
       "3                        Pose Estimation   \n",
       "4                       Face Recognition   \n",
       "..                                   ...   \n",
       "494                    Cell Segmentation   \n",
       "495  Clean-label Backdoor Attack (0.05%)   \n",
       "496           Clothes Landmark Detection   \n",
       "497          Co-Salient Object Detection   \n",
       "498                   Core set discovery   \n",
       "\n",
       "                                                script  \\\n",
       "0    Semantic Segmentation is a computer vision tas...   \n",
       "1    Object Detection is a computer vision task in ...   \n",
       "2    Image Classification is a fundamental task tha...   \n",
       "3    Pose Estimation is a computer vision task wher...   \n",
       "4    Facial Recognition is the task of making a pos...   \n",
       "..                                                 ...   \n",
       "494  Cell Segmentation is a task of splitting a mic...   \n",
       "495  This task has no description! Would you like t...   \n",
       "496  This task has no description! Would you like t...   \n",
       "497  Co-Salient Object Detection is a computational...   \n",
       "498  A core set in machine learning is defined as t...   \n",
       "\n",
       "                                                   url  \n",
       "0    https://paperswithcode.com/task/semantic-segme...  \n",
       "1     https://paperswithcode.com/task/object-detection  \n",
       "2    https://paperswithcode.com/task/image-classifi...  \n",
       "3      https://paperswithcode.com/task/pose-estimation  \n",
       "4     https://paperswithcode.com/task/face-recognition  \n",
       "..                                                 ...  \n",
       "494  https://paperswithcode.com/task/cell-segmentation  \n",
       "495  https://paperswithcode.com/task/clean-label-ba...  \n",
       "496  https://paperswithcode.com/task/clothes-landma...  \n",
       "497  https://paperswithcode.com/task/co-saliency-de...  \n",
       "498  https://paperswithcode.com/task/core-set-disco...  \n",
       "\n",
       "[499 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = pd.read_csv('./description.csv')\n",
    "description.script = description.script.fillna('There is NaN')\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpscript = []\n",
    "error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Semantic Segmentation)セマンティックセグメンテーションは、画像内の各ピクセルをクラスまたはオブジェクトに分類することを目標とするコンピュータービジョンタスクです。[0/499]\n",
      "(Object Detection)オブジェクトの検出は、目標が画像またはビデオで関心のあるオブジェクトを検出して見つけることであるコンピュータービジョンタスクです。[1/499]\n",
      "(Image Classification)画像分類は、画像全体を全体として理解しようとする基本的なタスクです。[2/499]\n",
      "(Pose Estimation)ポーズ推定は、人またはオブジェクトの位置と方向を検出することを目標とするコンピュータービジョンタスクです。[3/499]\n",
      "(Face Recognition)顔認識は、既存の顔のデータベースに対して写真またはビデオ画像で顔を肯定的に識別するタスクです。[4/499]\n",
      "(Visual Question Answering (VQA))視覚的な質問応答（VQA）は、画像に関する質問への回答を含むコンピュータービジョンのタスクです。[5/499]\n",
      "(Image Retrieval)画像検索は、特定のクエリ画像に似た大規模なデータベース内の画像を検索することを含むコンピュータービジョンタスクです。[6/499]\n",
      "(Depth Estimation)深さの推定は、カメラに対する各ピクセルの距離を測定するタスクです。[7/499]\n",
      "(Instance Segmentation)インスタンスセグメンテーションは、各オブジェクトの境界を検出したり、各オブジェクトに一意のラベルを割り当てるなど、画像内の個々のオブジェクトを識別および分離することを含むコンピュータービジョンタスクです。[8/499]\n",
      "(Image Generation)ドラゴン[9/499]\n",
      "(Question Answering)質問の回答は、質問に答えるタスク（通常は読解質問の質問）ですが、提供されたコンテキストに基づいて回答できない質問が提示された場合に棄権します。[10/499]\n",
      "(Optical Character Recognition (OCR))光学キャラクター認識または光学文字リーダー（OCR）は、スキャンされたドキュメント、ドキュメントの写真、シーンフォト（例えば、機械にエンコードされたテキストへのタイプ化された、手書きまたは印刷されたテキストの画像の電子的または機械的変換）です。[11/499]\n",
      "(Image Captioning)画像キャプションは、言葉で画像の内容を記述するタスクです。[12/499]\n",
      "(Domain Adaptation)ナンがあります[13/499]\n",
      "(Person Re-Identification)人の再識別とは、ビデオまたは画像シーケンスのさまざまなカメラや場所で人の身元を一致させることを目標とするコンピュータービジョンタスクです。[14/499]\n",
      "(Autonomous Driving)自律運転は、人間の伝導なしで車両を運転するタスクです。[15/499]\n",
      "(Face Detection)フェイス検出は、デジタル画像やビデオ内の人間の顔を自動的に識別して見つけることを伴うコンピュータービジョンタスクです。[16/499]\n",
      "(2D Semantic Segmentation)このタスクには説明がありません！[17/499]\n",
      "(Fine-Grained Image Classification)微調整された画像分類は、コンピュータービジョンのタスクであり、目標は画像をより大きなカテゴリ内のサブカテゴリに分類することです。[18/499]\n",
      "(Image Super-Resolution)画像の超解像度は、多くの場合、コンテンツと詳細を可能な限り維持しながら、多くの場合4倍以上の画像の解像度を増やすことを目標とする機械学習タスクです。[19/499]\n",
      "(Data Augmentation)データ増強には、さまざまな変更に基づいてデータの量を増やすために使用される手法が含まれ、元のデータセットの例の量を拡大します。[20/499]\n",
      "(Object Recognition)オブジェクト認識は、画像やビデオのオブジェクトの分類を検出するためのコンピュータービジョン技術です。[21/499]\n",
      "(Action Recognition)アクション認識は、ビデオや画像の人間の行動を認識することを含むコンピュータービジョンタスクです。[22/499]\n",
      "(Medical Image Segmentation)医療画像セグメンテーションは、医療画像を複数のセグメントに分割することを含むコンピュータービジョンタスクであり、各セグメントは画像の関心のある異なるオブジェクトまたは構造を表します。[23/499]\n",
      "(Visual Reasoning)視覚画像に関連する行動と推論を理解する能力[24/499]\n",
      "(Classification)分類は、データのセットを事前定義されたクラスまたはグループに分類するタスクです。[25/499]\n",
      "(Image-to-Image Translation)画像から画像への翻訳は、入力画像と出力イメージの間のマッピングを学習することを目標とするコンピュータービジョンと機械学習のタスクであり、出力画像を使用してスタイル転送などの特定のタスクを実行できるようにします。[26/499]\n",
      "(Anomaly Detection)異常検出は、データセット内の異常なパターンまたは予期しないパターンを識別するバイナリ分類であり、データの大部分から大幅に逸脱します。[27/499]\n",
      "(3D Human Pose Estimation)3Dヒューマンポーズ推定は、2D画像またはビデオからの体調と骨の3D位置と方向を推定することを含むコンピュータービジョンタスクです。[28/499]\n",
      "(Scene Understanding)シーンの理解は、シーンを理解するものです。[29/499]\n",
      "(Unsupervised Domain Adaptation)監視されていないドメインの適応は、ソースドメインから学んだ知識を、多くの注釈付きトレーニングの例を使用して、標的ドメインのみをターゲットにしていないデータのみを導入するための学習フレームワークです。[30/499]\n",
      "(Facial Expression Recognition (FER))表情表現認識（FER）は、人間の顔に描かれた感情的な表現を特定して分類することを目的としたコンピュータービジョンタスクです。[31/499]\n",
      "(Handwriting Recognition)画像ソース：ラベル付きデータがほとんどない履歴ドキュメントの手書き認識[32/499]\n",
      "(Few-Shot Image Classification)少数のショット画像分類は、各カテゴリのいくつかのラベル付けされた例のみを使用して、画像を事前定義されたカテゴリに分類するための機械学習モデルをトレーニングすることを含むコンピュータービジョンタスクです（通常は6つの例）。[33/499]\n",
      "(Metric Learning)メトリック学習の目標は、オブジェクトを埋め込み空間にマッピングする表現関数を学習することです。[34/499]\n",
      "(Object Tracking)オブジェクトトラッキングは、オブジェクト検出の初期セットを取得し、初期検出のそれぞれに一意のIDを作成し、ビデオ内のフレームを動き回ってID割り当てを維持しながら各オブジェクトを追跡するタスクです。[35/499]\n",
      "(2D object detection)このタスクには説明がありません！[36/499]\n",
      "(3D Pose Estimation)画像クレジット：GSNET：幾何学的およびシーン認識監督によるジョイントビークルのポーズと形状の再構築、ECCV'20[37/499]\n",
      "(Neural Architecture Search)ニューラルアーキテクチャ検索（NAS）は、小さなデータセットから大きなデータセットに転送できるモジュラーアーキテクチャを学習します。[38/499]\n",
      "(3D Object Detection)3Dオブジェクトの検出は、コンピュータービジョンのタスクであり、目標は、その形状、場所、および向きに基づいて3D環境のオブジェクトを識別して見つけることです。[39/499]\n",
      "(3D Reconstruction)ナンがあります[40/499]\n",
      "(Few-Shot Learning)少数のショット学習は、メタトレーニング段階でいくつかの関連するタスクで学習者がトレーニングされているメタラーニングの例であり、メタ中に、わずかな例で目に見えない（ただし関連）タスクによく一般化できるようにします。[41/499]\n",
      "(Object Counting)オブジェクトカウントタスクの目標は、単一の画像またはビデオシーケンスでオブジェクトインスタンスの数をカウントすることです。[42/499]\n",
      "(Image Clustering)グラウンドトゥルースラベルにアクセスすることなく、データセットを意味的に意味のあるクラスターに分割するモデル。[43/499]\n",
      "(Zero-Shot Learning)Zero-Shot Learning（ZSL）は、トレーニング中に見られなかったクラスを検出するモデルの能力です。[44/499]\n",
      "(Face Anti-Spoofing)顔のスプーフィングは、写真、ビデオ、マスク、または認可された人の顔の別の代替品を使用して、誤った顔の検証を防ぐタスクです。[45/499]\n",
      "(Image Inpainting)画像の開始は、画像内の欠落している領域を再構築するタスクです。[46/499]\n",
      "(Novel View Synthesis)指定されたソース画像とそのカメラポーズから任意のターゲットカメラのポーズでターゲット画像を合成します。[47/499]\n",
      "(Optical Flow Estimation)光フロー推定は、画像またはビデオシーケンスでオブジェクトの動きを計算することを含むコンピュータービジョンタスクです。[48/499]\n",
      "(Panoptic Segmentation)パノプティックセグメンテーションは、セマンティックセグメンテーションとインスタンスセグメンテーションを組み合わせて、シーンの包括的な理解を提供するコンピュータービジョンタスクです。[49/499]\n",
      "(Scene Text Recognition)このタスクのリーダーボードのシーンテキスト検出を参照してください。[50/499]\n",
      "(Face Verification)顔の検証は、2つの顔の画像が同じ人に属しているかどうかを判断することを含む、コンピュータービジョンにおける機械学習タスクです。[51/499]\n",
      "(Multi-Task Learning)マルチタスク学習は、1つまたはすべてのタスクのパフォーマンスを最大化しながら、複数の異なるタスクを同時に学習することを目的としています。[52/499]\n",
      "(Continual Learning)継続的な学習（増分学習、生涯学習とも呼ばれます）は、前のタスクから得られた知識を忘れずに、多数のタスクのモデルを順番に学習するための概念です。[53/499]\n",
      "(Cross-Modal Retrieval)クロスモーダル検索は、さまざまなモダリティにわたって検索タスクを実装するために使用されます。[54/499]\n",
      "(Density Estimation)密度推定の目標は、未知の密度の観測可能なデータセットの基礎となる確率密度分布の正確な説明を与えることです。[55/499]\n",
      "(Image Denoising)画像除去は、画像からノイズを削除することを伴うコンピュータービジョンタスクです。[56/499]\n",
      "(Monocular Depth Estimation)単眼深度推定は、単一の（単眼の）RGB画像を与えられた各ピクセルの深さ値（カメラに対する距離）を推定するタスクです。[57/499]\n",
      "(Multi-Label Classification)マルチラベル分類は、インスタンスが複数のラベルに関連付けられる可能性のある監視された学習問題です。[58/499]\n",
      "(Object Localization)オブジェクトのローカリゼーションは、通常、インスタンスを中心としたしっかりとトリミングされた境界ボックスを指定することにより、画像内の特定のオブジェクトカテゴリのインスタンスを見つけるタスクです。[59/499]\n",
      "(Scene Recognition)このタスクには説明がありません！[60/499]\n",
      "(Super-Resolution)スーパー解像度は、低解像度の入力から欠落している高周波の詳細を生成することにより、画像またはビデオの解像度を増やすことを伴うコンピュータービジョンのタスクです。[61/499]\n",
      "(Visual Localization)視覚的なローカリゼーションは、既知のシーンの視覚的表現と比較して、特定の画像のカメラポーズを推定する問題です。[62/499]\n",
      "(Visual Odometry)視覚的臭気は、視覚センサーによって収集されたデータを使用してロボットのポーズを推定することを中心的な目的とする情報融合の重要な領域です。[63/499]\n",
      "(Disentanglement)これは、主要な問題の基礎構造をその表現のばらばらの部分に解き放つ（または分離する）ことにより、データ効率的な方法で一連のタスクを解決するためのアプローチです。[64/499]\n",
      "(Domain Generalization)ドメイン一般化のアイデアは、1つまたは複数のトレーニングドメインから学習し、目に見えないドメインに適用できるドメインに存在するモデルを抽出することです。[65/499]\n",
      "(Face Alignment)顔のアライメントは、デジタル画像の面の幾何学的構造を識別し、翻訳、スケール、および回転に基づいて顔の標準的なアライメントを取得しようとするタスクです。[66/499]\n",
      "(Hand Pose Estimation)ハンドポーズの推定は、ビデオフレームの画像またはセットから手の関節を見つけるタスクです。[67/499]\n",
      "(Salient Object Detection)このタスクには説明がありません！[68/499]\n",
      "(2D Human Pose Estimation)人間のポーズ推定とは何ですか？[69/499]\n",
      "(Crowd Counting)群衆のカウントは、イメージの人々を数えるタスクです。[70/499]\n",
      "(Facial Landmark Detection)フェイシャルランドマークの検出は、目、鼻、口、あごなどの顔の特定のポイントまたはランドマークを検出およびローカライズすることを含むコンピュータービジョンタスクです。[71/499]\n",
      "(Lesion Segmentation)病変セグメンテーションは、医療ベースの画像の他のオブジェクトから病変を分割するタスクです。[72/499]\n",
      "(Long-tail Learning)視覚的認識で最も困難な問題の1つであるロングテールの学習は、長期にわたるクラスの分布に続く多数の画像から、パフォーマンスの良いモデルを訓練することを目指しています。[73/499]\n",
      "(Pedestrian Detection)歩行者の検出は、カメラから歩行者を検出するタスクです。[74/499]\n",
      "(Quantization)量子化は、ニューラルネットワークトレーニングの計算コストを削減するための有望な手法であり、高コストの浮動小数点数（たとえば、FLOAT32）を低コストの固定点数（例：INT8に置き換えることができます[75/499]\n",
      "(Saliency Detection)顕著性検出は、画像内の顕著なオブジェクトを見つけることを目的とするコンピュータービジョンの前処理ステップです。[76/499]\n",
      "(Self-Supervised Learning)自己教師の学習とは、自己教師の方法で表現を学習する方法のカテゴリーを指します（つまり、ラベルなし）。[77/499]\n",
      "(Semi-Supervised Image Classification)半学者の画像分類は、分類されたデータと分類パフォーマンスを向上させるためにラベル付けされたデータとラベル付けされたデータをレバレッジします。[78/499]\n",
      "(Stereo Matching)ステレオマッチングは、2D画像から実世界の3D構造を回復するコンピュータービジョンのコアテクノロジーの1つです。[79/499]\n",
      "(Video Prediction)ビデオ予測は、過去のビデオフレームが与えられた将来のフレームを予測するタスクです。[80/499]\n",
      "(Visual Object Tracking)視覚オブジェクト追跡は、コンピュータービジョン、画像理解、パターン認識における重要な研究トピックです。[81/499]\n",
      "(Age Estimation)年齢の推定は、画像から人の年齢を他の種類のデータから推定するタスクです。[82/499]\n",
      "(Autonomous Vehicles)自動運転車は、人間の伝導なしで自分自身を導くことができる車両を作るタスクです。[83/499]\n",
      "(Denoising)除去は、画像処理とコンピュータービジョンのタスクであり、画像からノイズを削除または削減することを目的としています。[84/499]\n",
      "(Human-Object Interaction Detection)ヒトとオブジェクトの相互作用（HOI）検出は、イメージの「相互作用のセット」を識別するタスクです。[85/499]\n",
      "(Image Segmentation)画像セグメンテーションは、画像を複数のセグメントまたは領域に分割することを含むコンピュータービジョンタスクであり、それぞれが異なるオブジェクトまたはオブジェクトの一部に対応します。[86/499]\n",
      "(Scene Classification)シーン分類は、写真のシーンがカテゴリー的に分類されるタスクです。[87/499]\n",
      "(Simultaneous Localization and Mapping)同時ローカリゼーションとマッピング（SLAM）は、不明な環境のマップを構築または更新しながら、同時にその中のエージェントの位置を追跡するタスクです。[88/499]\n",
      "(Skeleton Based Action Recognition)スケルトンベースのアクション認識は、Microsoft Kinect、Intel RealSense、ウェアラブルデバイスなどのセンサーからキャプチャされた一連の3D骨格ジョイントデータから人間のアクションを認識することを含むコンピュータービジョンタスクです。[89/499]\n",
      "(Trajectory Prediction)軌道予測は、車、バス、歩行者、人力車、動物などのさまざまな道路材の短期（1〜3秒）および長期（3〜5秒）の空間座標を予測する問題です。[90/499]\n",
      "(3D Hand Pose Estimation)画像：Zimmerman et l[92/499]\n",
      "(Common Sense Reasoning)常識推論タスクは、モデルがパターン認識を超えることを要求することを目的としています。[93/499]\n",
      "(Gaze Estimation)視線の推定は、人の顔を与えられた人がどこを見ているかを予測するタスクです。[94/499]\n",
      "(Image Compression)画像圧縮は、デジタル画像のデータ圧縮のアプリケーションであり、ストレージを下げ、[95/499]\n",
      "(Multi-Object Tracking)マルチオブジェクトトラッキングは、ビデオシーケンス内で複数のオブジェクトの検出と追跡を伴うコンピュータービジョンのタスクです。[96/499]\n",
      "(Object Detection In Indoor Scenes)屋内シーンでのオブジェクト検出は、屋内環境内でオブジェクト検出を実行するタスクです。[97/499]\n",
      "(RGB Salient Object Detection)RGB Salientオブジェクト検出は、視覚的な注意メカニズムに基づいたタスクベースであり、アルゴリズムは、シーンまたはRGB画像の周囲の領域よりも注意深いオブジェクトまたは領域を探索することを目的としています。[98/499]\n",
      "(Scene Text Detection)シーンテキストの検出は、自然な画像やビデオ内のテキストを自動的に識別およびローカライズすることを含むコンピュータービジョンタスクです。[99/499]\n",
      "(Text-to-Image Generation)テキストから画像の生成は、特定のテキスト説明に対応する画像を生成することを目標とするコンピュータービジョンと自然言語処理のタスクです。[100/499]\n",
      "(Vehicle Re-Identification)車両の再識別は、複数のカメラで同じ車両を識別するタスクです。[101/499]\n",
      "(Video Object Segmentation)ビデオオブジェクトのセグメンテーションは、ビデオの背景領域から前景オブジェクトを分離することを目的としたバイナリラベリングの問題です。[102/499]\n",
      "(Video Understanding)ビデオ理解の重要なタスクは、ビデオに表示されるさまざまなアクションまたはイベントを（空間と時間で）認識してローカライズすることです。[103/499]\n",
      "(Visual Place Recognition)視覚的な場所の認識は、別の時間に撮影された同じ場所の異なるビューで、場所のビューを一致させるタスクです。[104/499]\n",
      "(Weakly Supervised Object Detection)弱く監視されたオブジェクト検出（WSOD）は、画像タグの監視のみを備えたオブジェクト検出器をトレーニングするタスクです。[105/499]\n",
      "(3D Face Reconstruction)3Dフェイス再構築は、2D画像または一連の画像から人間の顔の3Dモデルを作成することを含むコンピュータービジョンタスクです。[106/499]\n",
      "(3D Instance Segmentation)画像：Occuseg[107/499]\n",
      "(3D Semantic Segmentation)3Dセマンティックセグメンテーションは、3Dポイントクラウドまたは3Dメッシュを意味的に意味のある部品または領域に分割することを含むコンピュータービジョンタスクです。[108/499]\n",
      "(Computed Tomography (CT))「コンピューター断層撮影」という用語（CT）は、X線の狭いビームが患者を対象とし、体の周りを素早く回転させ、マシンのコンピューターによって処理される信号を生成するコンピューター化されたX線イメージング手順を指します。[109/499]\n",
      "(Decision Making)意思決定は、異なるソースから、およびさまざまなレベルの確実性で（異なるレベルの抽象化の）データを分析し、他のデータソースよりも多くのデータソースを比較検討することで情報をマージし、可能な限りすべてを探索することによって結論に到達する複雑なタスクです。[110/499]\n",
      "(Generalized Zero-Shot Learning)このタスクには説明がありません！[111/499]\n",
      "(Gesture Recognition)ジェスチャー認識は、手話の自動認識、人間とロボットの相互作用、またはビデオゲームを制御する新しい方法などのアプリケーションを使用した積極的な研究分野です。[112/499]\n",
      "(Handwriting generation)手書き認識の逆。[113/499]\n",
      "(Handwritten Text Recognition)このタスクには説明がありません！[114/499]\n",
      "(Image Registration)画像登録は、さまざまなデータセットを1つの座標系に変換するプロセスです。[115/499]\n",
      "(Image Restoration)画像修復は、破損した入力画像から高品質の画像を取得するための逆の問題のファミリーです。[116/499]\n",
      "(Lane Detection)レーン検出は、道路シーンのビデオまたは画像で車線を駆動する境界を識別することを伴うコンピュータービジョンタスクです。[117/499]\n",
      "(Medical Diagnosis)医学的診断は、特定の危険因子、兆候、症状、および試験結果の評価に基づいて、患者が影響を受ける疾患を特定するプロセスです。[118/499]\n",
      "(Multimodal Deep Learning)マルチモーダルディープラーニングは、テキスト、画像、オーディオ、ビデオなどの複数のモダリティからの情報を組み合わせて、より正確で包括的な予測を行う一種のディープラーニングです。[119/499]\n",
      "(Out-of-Distribution Detection)分散または異常な例を検出します。[120/499]\n",
      "(Prompt Engineering)プロンプトエンジニアリングは、言語モデルから情報をより効率的に抽出するための多数のプロンプトを作成する慣行です。[121/499]\n",
      "(Small Data Image Classification)数百から数百のラベル付きトレーニングの例を使用した教師付き画像分類。[122/499]\n",
      "(Style Transfer)スタイル転送は、ある画像のコンテンツを別の画像のスタイルと組み合わせることにより、新しい画像を生成することを含むコンピュータービジョンとグラフィックスの手法です。[123/499]\n",
      "(Text Generation)テキスト生成は、人間が作成したテキストと見分けがつかないように見えることを目指して、テキストを生成するタスクです。[124/499]\n",
      "(Transfer Learning)転送学習は、1つのタスクでトレーニングされたモデルが再利用され、関連するが異なるタスクのために微調整されている機械学習手法です。[125/499]\n",
      "(Tumor Segmentation)腫瘍のセグメンテーションは、腫瘍の空間的位置を特定するタスクです。[126/499]\n",
      "(Unsupervised Semantic Segmentation)グラウンドトゥルースラベルを表示せずに、各画像をセグメント化することを学ぶ（つまり、すべてのピクセルにクラスを割り当てる）モデル。[127/499]\n",
      "(Visual Navigation)視覚ナビゲーションは、エージェントをナビゲートする問題です。[128/499]\n",
      "(Animal Pose Estimation)動物のポーズ推定は、動物のポーズを特定するタスクです。[129/499]\n",
      "(Color Image Denoising)このタスクには説明がありません！[130/499]\n",
      "(Conditional Image Generation)条件付き画像生成は、クラスを条件とするデータセットから新しい画像を生成するタスクです。[131/499]\n",
      "(Disaster Response)このタスクには説明がありません！[132/499]\n",
      "(Fine-Grained Image Recognition)このタスクには説明がありません！[133/499]\n",
      "(Generalizable Person Re-identification)一般化可能な人の再識別とは、ソースデータセットでトレーニングされた方法を指しますが、ドメインの適応または転送学習なしでターゲットデータセットで直接評価されます。[134/499]\n",
      "(Human Detection)このタスクには説明がありません！[135/499]\n",
      "(Human Part Segmentation)このタスクには説明がありません！[136/499]\n",
      "(Image Dehazing)（画像クレジット：密に接続されたピラミッド脱hazingネットワーク）[137/499]\n",
      "(Image Enhancement)画像の強化は、基本的に、人間の視聴者向けの画像の情報の解釈性または認識を改善し、他の自動化された画像処理技術に「より良い」入力を提供しています。[138/499]\n",
      "(Keypoint Detection)キーポイント検出には、同時に人を検出し、キーポイントをローカライズすることが含まれます。[139/499]\n",
      "(Lesion Classification)このタスクには説明がありません！[140/499]\n",
      "(License Plate Recognition)このタスクには説明がありません！[141/499]\n",
      "(Low-Light Image Enhancement)低光画像の強化は、低照度条件下でキャプチャされた画像の品質を改善することを伴うコンピュータービジョンタスクです。[142/499]\n",
      "(Real-Time Object Detection)リアルタイムオブジェクトの検出は、基本レベルの精度を維持しながら、高速推論を備えたリアルタイムビデオシーケンスで関心のあるオブジェクトを識別して特定することを伴うコンピュータービジョンタスクです。[143/499]\n",
      "(Real-Time Semantic Segmentation)セマンティックセグメンテーションは、画像内の各ピクセルにセマンティックラベルを割り当てることを含むコンピュータービジョンタスクです。[144/499]\n",
      "(Relational Reasoning)リレーショナル推論の目標は、画像ピクセル、単語や文、人間のスケルトン、インタラクティブな移動エージェントなど、さまざまなエンティティ間の関係を把握することです。[145/499]\n",
      "(Robust Object Detection)のベンチマーク：オブジェクト検出モデルの堅牢性腐敗と歪みを画像化する[146/499]\n",
      "(Stochastic Optimization)確率的最適化方法は、ニューラルネットワークを最適化するために使用されます。[147/499]\n",
      "(Surface Normals Estimation)表面通常の推定は、シーン内に存在するオブジェクトの表面向きを予測するタスクを扱います。[148/499]\n",
      "(Table Detection)画像クレジット：野生のテーブル検出：新しい多様なテーブル検出データセットと方法[149/499]\n",
      "(Text Classification)テキスト分類は、文または文書を適切なカテゴリに割り当てるタスクです。[150/499]\n",
      "(Unsupervised Semantic Segmentation with Language-image Pre-training)画像レベルのラベルで事前に訓練された機能で初期化されたバックボーンを除き、セマンティックセグメンテーションのために人間レベルの監督を使用しないセグメンテーションタスク。[151/499]\n",
      "(Visual Commonsense Reasoning)画像ソース：Visual Commonsense推論[152/499]\n",
      "(Visual Tracking)視覚追跡は、ロボットサービス、スマートサーベイランスシステム、自律運転、人間のコンピューターの相互作用など、さまざまな現実世界のアプリケーションを備えたコンピュータービジョンの分野における重要な積極的に研究された問題です。[153/499]\n",
      "(3D Depth Estimation)画像：Monodepth2[154/499]\n",
      "(3D Shape Reconstruction)画像クレジット：GSNET：幾何学的およびシーン認識監督によるジョイントビークルのポーズと形状の再構築、ECCV'20[155/499]\n",
      "(6D Pose Estimation)画像：Zeng et al[156/499]\n",
      "(Activity Recognition)人間の活動認識は、ビデオ入力を与えられた人間によって実行されたイベントを特定する問題です。[157/499]\n",
      "(Adversarial Robustness)敵対的な堅牢性は、さまざまな種類の敵対的攻撃の下で機械学習モデルの脆弱性を評価します。[158/499]\n",
      "(Blind Super-Resolution)このタスクには説明がありません！[159/499]\n",
      "(COVID-19 Diagnosis)Covid-19診断は、機械学習を持つ個人におけるCovid-19の存在を診断するタスクです。[160/499]\n",
      "(Colorectal Polyps Characterization)このタスクには説明がありません！[161/499]\n",
      "(Colorization)色付けは、画像表現を学ぶために口実として色付けに依存する自己監視アプローチです。[162/499]\n",
      "(Deblurring)DeBluringは、画像やビデオからぼやけたアーティファクトを削除して、元のシャープなコンテンツを復元するコンピュータービジョンタスクです。[163/499]\n",
      "(DeepFake Detection)DeepFake検出は、ディープラーニングテクニックを使用して生成された偽のビデオまたは画像を検出するタスクです。[164/499]\n",
      "(Depth Completion)深さ完了タスクは、深度推定のサブ問題です。[165/499]\n",
      "(Face Swapping)フェイススワッピングとは、身体と環境の文脈の残りを維持しながら、画像間またはビデオで顔を交換するタスクを指します。[166/499]\n",
      "(Fairness)このタスクには説明がありません！[167/499]\n",
      "(Food Recognition)このタスクには説明がありません！[168/499]\n",
      "(Graph Matching)グラフマッチングは、複雑なリレーショナル情報を保存しながら、2つの頂点間で対応を見つける問題です。[169/499]\n",
      "(Hyperspectral Image Classification)ハイパースペクトル画像分類は、リモートセンシングとコンピュータービジョンの分野でのタスクです。[170/499]\n",
      "(Image Quality Assessment)このタスクには説明がありません！[171/499]\n",
      "(Image-to-Text Retrieval)このタスクには説明がありません！[172/499]\n",
      "(Incremental Learning)Incremental Learningは、以前に学んだタスクから学んだ知識を維持しながら、新しいデータからの新しいタスクに対処することを継続的に学習できる人工的にインテリジェントなシステムを開発することを目的としています。[173/499]\n",
      "(Information Retrieval)情報検索は、クエリに応じてドキュメントまたは検索結果のリストをランキングするタスクです[174/499]\n",
      "(Language Modelling)言語モデリングは、ドキュメント内の次の単語または文字を予測するタスクです。[175/499]\n",
      "(Learning with noisy labels)ノイズの多いラベルで学ぶことは、「ノイズの多いラベル」と言うとき、敵が意図的にラベルを台無しにしたことを意味します。[176/499]\n",
      "(License Plate Detection)ナンバープレート認識は、ナンバープレートで車両を識別するために使用される画像処理テクノロジーです。[177/499]\n",
      "(Multi-Label Image Classification)マルチラベル画像分類は、各画像が複数のクラスに属する可能性のあるマルチクラス分類問題の画像のラベルの予測に焦点を当てています。[178/499]\n",
      "(Multiple Object Tracking)複数のオブジェクト追跡は、ビデオ内の複数のオブジェクトを自動的に識別し、それらを高精度のある一連の軌跡として表す問題です。[179/499]\n",
      "(Node Classification)ノード分類は、グラフベースのデータ分析における機械学習タスクであり、目標は、ノードのプロパティとそれらの間の関係に基づいてグラフのノードにラベルを割り当てることです。[180/499]\n",
      "(Optical Charater Recogntion)このタスクには説明がありません！[181/499]\n",
      "(Phrase Grounding)画像と対応するキャプションを与えられたフレーズの接地タスクは、キャプション内の名詞句で言及された各エンティティを画像内の領域に接地することを目的としています。[182/499]\n",
      "(Pose Prediction)ポーズ予測は、以前のポーズのウィンドウを考慮して、将来のポーズを予測することです。[183/499]\n",
      "(Single-View 3D Reconstruction)このタスクには説明がありません！[184/499]\n",
      "(Speech Recognition)ナンがあります[185/499]\n",
      "(Temporal Action Localization)一時的なアクションローカリゼーションは、ビデオストリームのアクティビティと出力の開始および終了タイムスタンプを検出することを目的としています。[186/499]\n",
      "(Unsupervised Image Classification)グラウンドトゥルースラベルを見ることなく、各画像（つまり、データセットをグラウンドトゥルースクラスにクラスター化する）を学ぶモデル。[187/499]\n",
      "(Vision-Language Navigation)Vision-Language Navigation（VLN）は、具体化されたエージェントをナビゲートして、実際の3D環境内で自然言語の指示を実行するタスクです。[188/499]\n",
      "(Visual Dialog)視覚的なダイアログでは、AIエージェントが視覚コンテンツに関する自然な会話言語で人間と意味のあるダイアログを保持する必要があります。[189/499]\n",
      "(Zero-Shot Object Detection)ゼロショットオブジェクト検出（ZSD）は、ターゲットオブジェクトクラスの一部で視覚的なトレーニングデータが利用できないオブジェクト検出のタスクです。[190/499]\n",
      "(Zero-Shot Transfer Image Classification)このタスクには説明がありません！[191/499]\n",
      "(3D Absolute Human Pose Estimation)このタスクは、絶対（カメラ中心の根相対的ではない）3Dヒトポーズ推定を解決することを目的としています。[192/499]\n",
      "(3D Human Reconstruction)このタスクには説明がありません！[193/499]\n",
      "(3D Human Shape Estimation)このタスクには説明がありません！[194/499]\n",
      "(Active Learning)ナンがあります[195/499]\n",
      "(Adversarial Defense)現在未発表の結果を伴う競争：[196/499]\n",
      "(Class-agnostic Object Detection)クラスに依存しないオブジェクト検出は、カテゴリを指定せずに画像内のオブジェクトをローカライズすることを目的としています。[197/499]\n",
      "(Dictionary Learning)辞書学習は、計算神経科学、機械学習、コンピュータービジョン、画像処理まで、複数の分野で重要な問題です。[198/499]\n",
      "(Document Layout Analysis)「ドキュメントレイアウト分析は、ドキュメントの物理構造、つまりドキュメントコンポーネントを決定するために実行されます。これらのドキュメントコンポーネントは、単一領域を形成するために隣接するピクセルの単一接続コンポーネント - 領域[...]で構成できます[..[199/499]\n",
      "(Emotion Recognition)感情認識は、効果的な人間コンピューターの相互作用を可能にする研究の重要な分野です。[200/499]\n",
      "(Face Sketch Synthesis)フェイススケッチの合成は、入力フェイス写真からスケッチを生成するタスクです。[201/499]\n",
      "(Facial Attribute Classification)顔の属性分類は、顔のイメージのさまざまな属性を分類するタスクです。[202/499]\n",
      "(Few-Shot Object Detection)少ないショットオブジェクト検出は、限られたトレーニングデータを持つ画像のオブジェクトを検出することを含むコンピュータービジョンタスクです。[203/499]\n",
      "(Font Recognition)フォント認識（Visual Font認識または光学フォント認識とも呼ばれます）は、テキストを含む画像で使用されるフォントファミリまたはファミリを識別するタスクです。[204/499]\n",
      "(Gait Recognition)（画像クレジット：Gaitset：Gaitをクロスビューゲート認識のセットと見なしてください）[205/499]\n",
      "(General Classification)分類の一般的なタスクを解決しようとするアルゴリズム。[206/499]\n",
      "(Hand Gesture Recognition)このタスクには説明がありません！[207/499]\n",
      "(Hand-Gesture Recognition)このタスクには説明がありません！[208/499]\n",
      "(Head Pose Estimation)人のヘッドポーズを推定することは、視線の推定を支援する、注意のモデリング、3Dモデルの適合、ビデオへの適合、顔のアライメントの実行など、大量のアプリケーションを備えた重要な問題です。[209/499]\n",
      "(Homography Estimation)ホモグラフィーの推定は、同じシーンの2つの画像間の関係を見つけるためにコンピュータービジョンと画像処理で使用される手法ですが、異なる視点からキャプチャされます。[210/499]\n",
      "(Image Deblurring)このタスクには説明がありません！[211/499]\n",
      "(Image-Based Localization)クロスビューマッチングに基づいて、GPSなしの画像の位置を決定します。[212/499]\n",
      "(Intrinsic Image Decomposition)固有の画像分解とは、画像を反射率（アルベド）やシェーディング（照明）などの形成成分に分離するプロセスです。[213/499]\n",
      "(Material Recognition)このタスクには説明がありません！[214/499]\n",
      "(Meta-Learning)メタラーニングは、機械学習アルゴリズムを「学習する」ことで考慮される方法論です。[215/499]\n",
      "(Multi-Person Pose Estimation)マルチパーソンのポーズ推定は、1つのフレームで複数の人々のポーズを推定するタスクです。[216/499]\n",
      "(Object Proposal Generation)オブジェクトプロポーザル生成は、オブジェクトの検索をガイドし、画像間の徹底的なスライディングウィンドウ検索を避けるために、現在のオブジェクト検出パイプラインで広く使用されている前処理手法です。[217/499]\n",
      "(Outlier Detection)外れ値検出は、他のインスタンスとは異常であるという点で異常と見なされる特定のデータセットのサブセットを識別するタスクです。[218/499]\n",
      "(Partial Domain Adaptation)部分的なドメイン適応は転送学習パラダイムであり、関連する知識を大規模なソースドメインから小規模なターゲットドメインに転送することができます。[219/499]\n",
      "(Person Search)人の検索は、多くのシーン画像の中で特定の人を一致させることを目的とするタスクです。[220/499]\n",
      "(Personalized Federated Learning)フェデレーションの学習セットアップは、データの不均一性（データ分布の違い）、デバイスの不均一性（計算能力、ネットワーク接続などの観点から）、通信効率など、多くの課題を提示します。[221/499]\n",
      "(Question Generation)質問生成の目標は、特定の文章とターゲットの答えに従って、有効で流fluentな質問を生成することです。[222/499]\n",
      "(RGB-D Salient Object Detection)RGB-D Salientオブジェクト検出（SOD）は、指定されたRGBおよび深度データのシーン内の最も視覚的に特徴的なオブジェクトまたは領域を区別することを目的としています。[223/499]\n",
      "(Remote Sensing Image Classification)このタスクには説明がありません！[224/499]\n",
      "(Retinal Vessel Segmentation)網膜容器セグメンテーションは、網膜画像の容器をセグメント化するタスクです。[225/499]\n",
      "(Self-Driving Cars)自動運転車：人間の指導なしで自動車を運転できる車を作るタスク。[226/499]\n",
      "(Unsupervised Video Object Segmentation)監視されていないシナリオは、ユーザーがアルゴリズムと対話してセグメンテーションマスクを取得しないことを前提としています。[231/499]\n",
      "(Video Inpainting)ビデオインペインティングの目標は、特定のビデオシーケンスの欠落している領域を、空間的および時間的にコヒーレントの両方の内容を記入することです。[232/499]\n",
      "(Video Segmentation)このタスクには説明がありません！[233/499]\n",
      "(Virtual Try-on)衣類やメイクなどの衣類やその他のアイテムの仮想試行。[234/499]\n",
      "(3D Action Recognition)画像：Rahmani et al[235/499]\n",
      "(3D Face Modelling)このタスクには説明がありません！[236/499]\n",
      "(3D Medical Imaging Segmentation)3D医療イメージングセグメンテーションは、3D医療イメージングから関心のある医療オブジェクトをセグメント化するタスクです。[237/499]\n",
      "(3D Object Recognition)3Dオブジェクト認識は、3Dデータからオブジェクトを認識するタスクです。[238/499]\n",
      "(3D Object Tracking)このタスクには説明がありません！[239/499]\n",
      "(6D Pose Estimation using RGB)RGBを使用した6Dポーズ推定とは、RGB画像に基づいて3Dスペースの6つの宇宙（6D）ポーズを決定するタスクを指します。[240/499]\n",
      "(Action Segmentation)アクションセグメンテーションは、高レベルのビデオ理解における困難な問題です。[241/499]\n",
      "(Action Triplet Recognition)対象動詞とオブジェクトの三重項としてアクションを認識します。[242/499]\n",
      "(Atari Games)Atari 2600 Gamesタスク（およびデータセット）には、高いゲームスコアを達成するためにエージェントをトレーニングすることが含まれます。[243/499]\n",
      "(Binarization)このタスクには説明がありません！[244/499]\n",
      "(Brain Tumor Segmentation)脳腫瘍のセグメンテーションは、磁気共鳴画像法（MRI）スキャンにおける正常な脳組織からの脳腫瘍の分離を含む医療画像分析タスクです。[245/499]\n",
      "(Breast Cancer Detection)このタスクには説明がありません！[246/499]\n",
      "(Breast Tumour Classification)このタスクには説明がありません！[247/499]\n",
      "(Classification with Binary Weight Network)このタスクには説明がありません！[248/499]\n",
      "(Compressive Sensing)圧縮センシングは、固定線形ベースでスパース表現を持つ信号を効率的に取得および再構築するための新しい信号処理フレームワークです。[249/499]\n",
      "(Content-Based Image Retrieval)コンテンツベースの画像検索は、コンピュータービジョンのよく研究された問題であり、検索の問題は一般にカテゴリレベルの検索とインスタンスレベルの検索の2つのグループに分かれています。[250/499]\n",
      "(Coreference Resolution)コアレファレンスの解決は、同じ基礎となる現実世界の実体を指すテキストでのクラスタリングの言及のタスクです。[251/499]\n",
      "(Defect Detection)さまざまな製品の表面欠陥の自動検出用[252/499]\n",
      "(Dimensionality Reduction)次元削減方法は、データを高次元空間から低次元空間に変換し、低次元空間が元のデータの最も重要な特性を保持するようにします。[253/499]\n",
      "(Edge Detection)エッジ検出は、画像勾配を計算して画像内のエッジの大きさと方向を定量化する基本的な画像処理手法です。[254/499]\n",
      "(Entity Linking)テキストに記載されているエンティティ（有名な個人、場所、企業など）にユニークなアイデンティティを割り当てる（出典：Wikipedia）。[255/499]\n",
      "(Explanation Generation)このタスクには説明がありません！[256/499]\n",
      "(Face Identification)顔の識別は、特定のフェイス画像を既存の顔のデータベースの顔画像と一致させるタスクです。[257/499]\n",
      "(Face Parsing)特定の境界ボックスに基づいて、フェイス画像のピクセルを異なるクラスに分類します。[258/499]\n",
      "(Face Presentation Attack Detection)このタスクには説明がありません！[259/499]\n",
      "(Facial Action Unit Detection)フェイシャルアクションユニットの検出は、顔のビデオからアクションユニットを検出するタスクです。たとえば、唇の引き締めや頬の飼育です。[260/499]\n",
      "(Fine-Grained Visual Categorization)このタスクには説明がありません！[261/499]\n",
      "(Fine-Grained Visual Recognition)このタスクには説明がありません！[262/499]\n",
      "(Graph Classification)グラフ分類は、グラフ構造データをさまざまなクラスまたはカテゴリに分類することを含むタスクです。[263/499]\n",
      "(Handwritten Digit Recognition)このタスクには説明がありません！[264/499]\n",
      "(Human Behavior Forecasting)このタスクには説明がありません！[265/499]\n",
      "(Image Classification with Label Noise)このタスクには説明がありません！[266/499]\n",
      "(Image Compressed Sensing)このタスクには説明がありません！[267/499]\n",
      "(Image Reconstruction)このタスクには説明がありません！[268/499]\n",
      "(Image Stitching)画像ステッチは、狭いが重複する視野で複数の画像を作成して、より広い視野を持つより大きな画像を作成するプロセスです。[269/499]\n",
      "(Image-based Automatic Meter Reading)このタスクには説明がありません！[270/499]\n",
      "(Imitation Learning)模倣学習は、デモンストレーションから行動ポリシーを学習するためのフレームワークです。[271/499]\n",
      "(Interactive Segmentation)このタスクには説明がありません！[272/499]\n",
      "(JPEG Artifact Correction)JPEG圧縮によって引き起こされる視覚アーティファクトの補正、これらのアーティファクトは通常、ブロッキング、ぼやけ、鳴り響きの3つのタイプにグループ化されます。[273/499]\n",
      "(Knowledge Distillation)ほぼすべての機械学習アルゴリズムのパフォーマンスを改善する非常に簡単な方法は、同じデータで多くの異なるモデルをトレーニングし、その予測を平均化することです。[274/499]\n",
      "(Learning with coarse labels)ラベルコストを大幅に削減できる、粗くラベルされたデータセットで細粒表現を学習することができます。[275/499]\n",
      "(Line Segment Detection)このタスクには説明がありません！[276/499]\n",
      "(MRI Reconstruction)最も基本的な形式では、MRI再構成は、サンプリングされていないフーリエ係数から複雑な値画像を取得することにあります。[277/499]\n",
      "(Medical Image Generation)医療画像生成は、新しい医療画像を統合するタスクです。[278/499]\n",
      "(Meter Reading)このタスクには説明がありません！[279/499]\n",
      "(Misinformation)このタスクには説明がありません！[280/499]\n",
      "(Monocular 3D Human Pose Estimation)このタスクは、単一のRGBカメラを使用した3Dヒューマンポーズ推定をターゲットにします。[281/499]\n",
      "(Monocular Visual Odometry)このタスクには説明がありません！[282/499]\n",
      "(Motion Forecasting)モーション予測は、将来追跡されたオブジェクトの位置を予測するタスクです[283/499]\n",
      "(Multi-Label Learning)このタスクには説明がありません！[284/499]\n",
      "(Multi-Modal Document Classification)このタスクには説明がありません！[285/499]\n",
      "(Multimodal Activity Recognition)このタスクには説明がありません！[286/499]\n",
      "(Natural Language Understanding)自然言語理解は、テキスト分類、自然言語の推論、ストーリーの理解などのさまざまなタスクを含む自然言語処理の重要な分野です。[287/499]\n",
      "(Network Pruning)ネットワークプルーニングは、重いネットワークの冗長性を削除することにより、重いネットワークを減らして軽量のフォームを取得するための一般的なアプローチです。[288/499]\n",
      "(Object Detection In Aerial Images)空中画像のオブジェクト検出は、航空画像からオブジェクトを検出するタスクです。[289/499]\n",
      "(Open Vocabulary Object Detection)オープンボキャブラリー検出（OVD）は、トレーニング段階でラベル付けされた限られた数の基本クラスを超えて一般化することを目的としています。[290/499]\n",
      "(Open World Object Detection)オープンワールドオブジェクトの検出は、モデルに次のような任務を課されるコンピュータービジョンの問題です。1）「不明」として導入されていないオブジェクトを特定することなく、2）忘れずにこれらの特定された未知のカテゴリを段階的に学習する[291/499]\n",
      "(Pedestrian Attribute Recognition)歩行者の帰属認識は、電話で話しているかどうか、バックパックがあるかなど、歩行者の特徴を認識するタスクです。[292/499]\n",
      "(Pose Transfer)このタスクには説明がありません！[293/499]\n",
      "(Recommendation Systems)ナンがあります[294/499]\n",
      "(Referring Expression Comprehension)このタスクには説明がありません！[295/499]\n",
      "(Referring Expression Segmentation)タスクの目的は、言語式で言及されているオブジェクトインスタンスを表す画像またはビデオのピクセルにラベルを付けることを目的としています。[296/499]\n",
      "(Representation Learning)ナンがあります[297/499]\n",
      "(Robotic Grasping)このタスクは、ディープラーニングを使用して、さまざまなシナリオでロボットアームを使用してオブジェクトを把握する最善の方法を特定することで構成されています。[298/499]\n",
      "(SSIM)このタスクには説明がありません！[299/499]\n",
      "(Saliency Prediction)顕著性マップは、視覚シーンでの目の固定を予測するモデルです。[300/499]\n",
      "(Scene Graph Generation)シーングラフは、シーングラフのノードがオブジェクトカテゴリを持つオブジェクトの境界ボックスに対応し、エッジがオブジェクト間のペアワイズ関係に対応する画像の構造化された表現です。[301/499]\n",
      "(Scene Parsing)シーンの解析は、空、道路、人、ベッドなどのセマンティックカテゴリに関連するさまざまな画像領域に画像をセグメント化して解析することです。[302/499]\n",
      "(Scene Segmentation)シーンセグメンテーションは、シーンをさまざまなオブジェクトコンポーネントに分割するタスクです。[303/499]\n",
      "(Semi-Supervised Video Object Segmentation)半監視されたシナリオは、ユーザーがビデオシーケンスの最初のフレームに関心のあるオブジェクトの完全なマスクを入力することを想定しています。[304/499]\n",
      "(Sentiment Analysis)感情分析は、特定のテキストの極性を分類するタスクです。[305/499]\n",
      "(Single Image Dehazing)このタスクには説明がありません！[306/499]\n",
      "(Sketch-Based Image Retrieval)このタスクには説明がありません！[307/499]\n",
      "(Sketch-to-Image Translation)このタスクには説明がありません！[308/499]\n",
      "(Skin Lesion Classification)このタスクには説明がありません！[309/499]\n",
      "(Stereo Matching Hand)このタスクには説明がありません！[310/499]\n",
      "(Symmetry Detection)このタスクには説明がありません！[311/499]\n",
      "(Table Recognition)このタスクには説明がありません！[312/499]\n",
      "(Unsupervised Object Segmentation)画像クレジット：Clevrtex：監視されていないマルチオブジェクトセグメンテーションのためのテクスチャリッチベンチマーク[314/499]\n",
      "(Variational Inference)ソース：[315/499]\n",
      "(Video Classification)ビデオ分類は、フレームを考慮してビデオに関連するラベルを作成するタスクです。[316/499]\n",
      "(Video Retrieval)ビデオ取得の目的は次のとおりです。テキストクエリと候補ビデオのプールを与えられた場合、テキストクエリに対応するビデオを選択します。[317/499]\n",
      "(Video Semantic Segmentation)このタスクには説明がありません！[318/499]\n",
      "(Video Super-Resolution)ビデオスーパー解像度は、ビデオシーケンスの解像度を増やすことを目的としたコンピュータービジョンタスクです。通常は、通常は低解像度から高解像度になります。[319/499]\n",
      "(Vision and Language Navigation)このタスクには説明がありません！[320/499]\n",
      "(Visual Relationship Detection)視覚関係検出（VRD）は、画像内のオブジェクト間の関係や相互作用を認識することを目的とした、新しく開発されたコンピュータービジョンタスクの1つです。[321/499]\n",
      "(motion prediction)このタスクには説明がありません！[322/499]\n",
      "(3D Facial Expression Recognition)3D表現認識は、画像またはビデオから3Dの表情をモデル化するタスクです。[323/499]\n",
      "(3D Human Pose Tracking)このタスクには説明がありません！[324/499]\n",
      "(3D Multi-Person Pose Estimation)このタスクは、根相対的な3Dマルチパーソンポーズ推定を解決することを目的としています。[325/499]\n",
      "(3D Object Reconstruction)画像：Choy et al[326/499]\n",
      "(3D Point Cloud Reconstruction)3Dポイント雲のエンコードと再構築。[327/499]\n",
      "(Abnormal Event Detection In Video)ビデオでの異常なイベントの検出は、異常なイベントがどのように見えるかの定義はコンテキストに大きく依存するため、コンピュータービジョンの挑戦的なタスクです。[328/499]\n",
      "(Action Detection)このタスクには説明がありません！[329/499]\n",
      "(Action Recognition In Videos)ビデオのアクション認識は、ビデオシーケンスで実行される人間のアクションを特定して分類することであるコンピュータービジョンとパターン認識のタスクです。[330/499]\n",
      "(Action Unit Detection)アクションユニットの検出は、ビデオからアクションユニットを検出するタスクです。たとえば、顔のビデオからの顔のアクションユニット（唇の引き締め、頬の上昇）の種類です。[331/499]\n",
      "(Age And Gender Classification)年齢と性別の分類は、画像やビデオの人の年齢と性別を識別するためのデュアルタスクです。[332/499]\n",
      "(Age-Invariant Face Recognition)年齢不変の顔認識は、年齢の違いに不変の顔認識を実行するタスクです。[333/499]\n",
      "(Blended-target Domain Adaptation)ブレンドターゲットドメインの適応は、単一のソースモデルを複数の異なるターゲットドメインに適応させることです。[334/499]\n",
      "(Blind Face Restoration)ブラインドフェイス修復は、低解像度、騒音、ぼやけ、圧縮アーティファクトなど、不明な分解に苦しむ低品質の対応物から高品質の顔を回復することを目的としています。実際のシナリオに適用すると、より挑戦的になります。[335/499]\n",
      "(Body Detection)データセットで定義されている人または文字の検出。[336/499]\n",
      "(Boundary Detection)境界検出は、画像にエンコードされた情報を抽出する重要な部分であり、密度、速度、圧力などを含む関心の量の計算を可能にします。[337/499]\n",
      "(Camera Calibration)このタスクには説明がありません！[338/499]\n",
      "(Camera Localization)このタスクには説明がありません！[339/499]\n",
      "(Change Detection)変更検出は、時間の経過とともに画像またはビデオシーケンスの変更を検出することを伴うコンピュータービジョンタスクです。[340/499]\n",
      "(Chart Question Answering)チャートの画像の質問に答える[341/499]\n",
      "(Classification with Binary Neural Network)このタスクには説明がありません！[342/499]\n",
      "(Cloud Removal)宇宙生まれの衛星を介して収集されたすべての光学観測の大部分は、ヘイズまたは雲の影響を受けます。[343/499]\n",
      "(Clustering Algorithms Evaluation)このタスクには説明がありません！[344/499]\n",
      "(Color Constancy)色の恒常性は、人間のビジョンシステムが光源の色に主に不変のシーン内のオブジェクトの色を知覚する能力です。[345/499]\n",
      "(Compositional Zero-Shot Learning)このタスクには説明がありません！[346/499]\n",
      "(Contrastive Learning)ナンがあります[347/499]\n",
      "(Cross-Modal Person Re-Identification)このタスクには説明がありません！[348/499]\n",
      "(Cross-View Image-to-Image Translation)このタスクには説明がありません！[349/499]\n",
      "(Dense Object Detection)このタスクには説明がありません！[350/499]\n",
      "(Dense Pixel Correspondence Estimation)このタスクには説明がありません！[351/499]\n",
      "(Diabetic Retinopathy Grading)（眼科）眼底画像からの糖尿病性網膜症の重症度を評価する[352/499]\n",
      "(Dialogue Generation)対話の生成は、自然言語の入力を「理解」するタスクです。これは、生産量を生成するための自然言語処理内です。[353/499]\n",
      "(Disparity Estimation)格差の推定は、シーンの同じ3Dポイントに対応するマルチソピックビューでピクセルを見つけるタスクです。[354/499]\n",
      "(Document Text Classification)このタスクには説明がありません！[355/499]\n",
      "(Driver Attention Monitoring)ドライバーの注意監視は、ドライバーの注意を監視するタスクです。[356/499]\n",
      "(Explainable artificial intelligence)Xaiは、人工知能（AI）の適用における方法と技術を指し、解決策の結果が人間が理解できるようにします。[357/499]\n",
      "(Face Generation)顔の生成は、既存のデータセットから新しい顔を生成（または補間）するタスクです。[358/499]\n",
      "(Face Hallucination)顔の幻覚は、低解像度（LR）入力から高解像度（HR）顔の画像を生成するタスクです。[359/499]\n",
      "(Face Model)このタスクには説明がありません！[360/499]\n",
      "(Facial Emotion Recognition)顔の画像からの感情認識[361/499]\n",
      "(Facial Inpainting)顔の開始（または顔の完成）は、フェイス画像に欠落しているピクセルのもっともらしい顔の構造を生成するタスクです。[362/499]\n",
      "(Fake News Detection)偽のニュース検出は、ニュース記事やその他の種類のテキストを現実または偽物として識別および分類することを伴う自然言語処理タスクです。[363/499]\n",
      "(Feature Importance)このタスクには説明がありません！[364/499]\n",
      "(Few-Shot Semantic Segmentation)少数のセマンティックセグメンテーション（FSS）は、ピクセルごとの注釈付きサポート画像がほとんどない場合、クエリ画像のターゲットオブジェクトをセグメント化することを学びます。[365/499]\n",
      "(Fovea Detection)このタスクには説明がありません！[366/499]\n",
      "(Gaze Prediction)このタスクには説明がありません！[367/499]\n",
      "(Gender Bias Detection)このタスクには説明がありません！[368/499]\n",
      "(Generalized Few-Shot Learning)このタスクには説明がありません！[369/499]\n",
      "(Grasp Contact Prediction)オブジェクトとハンド（人間またはロボット）の接触を予測します。[370/499]\n",
      "(Grayscale Image Denoising)このタスクには説明がありません！[371/499]\n",
      "(Hand Segmentation)このタスクには説明がありません！[372/499]\n",
      "(Handwriting Verification)手書きの検証の目標は、指定された手書きのサンプルが同じ作家によって書かれているかどうかにかかわらず、自信の尺度を見つけることです。[373/499]\n",
      "(Histopathological Image Classification)このタスクには説明がありません！[374/499]\n",
      "(Human action generation)Yan et al。[375/499]\n",
      "(Image Cropping)画像のトリミングは一般的な写真操作プロセスであり、不要な領域を除去することで全体的な構成を改善します。[376/499]\n",
      "(Image Forensics)このタスクには説明がありません！[377/499]\n",
      "(Image Manipulation)このタスクには説明がありません！[378/499]\n",
      "(Joint Demosaicing and Denoising)このタスクには説明がありません！[379/499]\n",
      "(Layout-to-Image Generation)レイアウトから画像への生成指定されたレイアウトに基づいてシーンを生成するタスク。[380/499]\n",
      "(Lung Nodule Detection)このタスクには説明がありません！[381/499]\n",
      "(Machine Translation)機械の翻訳は、ソース言語の文を別のターゲット言語に翻訳するタスクです。[382/499]\n",
      "(Material Classification)このタスクには説明がありません！[383/499]\n",
      "(Medical Image Classification)医療画像分類は、X線、MRIスキャン、CTスキャンなどの医療画像を、画像の種類または特定の構造または疾患の存在に基づいて異なるカテゴリに分類することを含む医療画像分析のタスクです。[384/499]\n",
      "(Medical Image Registration)画像登録は、画像の融合または画像マッチングとも呼ばれ、画像の外観に基づいて2つ以上の画像を調整するプロセスです。[385/499]\n",
      "(Meme Classification)ミーム分類とは、インターネットミームを分類するタスクを指します。[386/499]\n",
      "(Micro-Expression Recognition)顔の微小表現認識は、ハイステーク環境で抑制された感情を特定する上で困難な作業であり、多くの場合、非常に短い期間と微妙な変化があります。[387/499]\n",
      "(Model Poisoning)このタスクには説明がありません！[388/499]\n",
      "(Monocular 3D Object Detection)単眼3Dオブジェクト検出は、単一の2D RGB画像でオブジェクトの周りに3D境界ボックスを描画するタスクです。[389/499]\n",
      "(Motion Estimation)モーション推定は、2つのフレーム間のブロックごとまたはピクセルごとのモーションベクトルを決定するために使用されます。[390/499]\n",
      "(Multi-Human Parsing)複数の人間の解析は、混雑したシーンで複数の人間を解析するタスクです。[391/499]\n",
      "(Multi-Source Unsupervised Domain Adaptation)このタスクには説明がありません！[392/499]\n",
      "(Multi-object discovery)このタスクには説明がありません！[393/499]\n",
      "(Multi-target Domain Adaptation)マルチターゲットドメイン適応のアイデアは、単一のラベル付きソースドメインから複数の非標識ターゲットドメインにモデルを適応させることです。[394/499]\n",
      "(Multi-tissue Nucleus Segmentation)このタスクには説明がありません！[395/499]\n",
      "(Multimodal Sentiment Analysis)マルチモーダル感情分析は、複数のデータソースを使用して感情分析を実行するタスクです。[396/499]\n",
      "(Multimodal Unsupervised Image-To-Image Translation)マルチモーダル監督なしの画像から画像への翻訳は、別のドメイン内の単一の画像から1つのドメインに複数の翻訳を生成するタスクです。[397/499]\n",
      "(Multiview Detection)大量に閉塞されたシナリオで検出するために複数のカメラビューを組み込む。[398/499]\n",
      "(Named Entity Recognition (NER))名前付きエンティティ認識（NER）は、自然言語処理（NLP）のタスクです。これは、名前、組織、場所などの事前定義されたカテゴリにテキスト内の名前のエンティティを識別および分類します。[399/499]\n",
      "(Neural Rendering)何らかの種類の3Dシーン（ポイントクラウド、メッシュ、ボクセルなど）の表現を考えると、タスクは、任意の視点からこのシーンの光エアリスティックなレンダリングを生成できるアルゴリズムを作成することです。[400/499]\n",
      "(Novel Class Discovery)Nove Class Discovery（NCD）の目標は、既知のクラスからの事前知識を活用することにより、非標識データの新しいクラスを特定することです。[401/499]\n",
      "(One-Shot Learning)ワンショット学習は、単一のトレーニング例からオブジェクトカテゴリに関する情報を学習するタスクです。[402/499]\n",
      "(One-Shot Object Detection)（画像クレジット：シャムマスクR-CNN）[403/499]\n",
      "(One-stage Anchor-free Oriented Object Detection)このタスクには説明がありません！[404/499]\n",
      "(Online Multi-Object Tracking)オンラインマルチオブジェクトトラッキングの目標は、オンラインビデオストリーム内の複数のオブジェクトの時空間的軌跡（つまり、ビデオがフレームごとに提供される）を推定することです。これは、多数のリアルタイムアプリケーションの基本的な問題です。[405/499]\n",
      "(Open-World Semi-Supervised Learning)このタスクには説明がありません！[406/499]\n",
      "(Optic Disc Detection)光学板の地域提案[407/499]\n",
      "(Optic Disc Segmentation)このタスクには説明がありません！[408/499]\n",
      "(Patch Matching)このタスクには説明がありません！[409/499]\n",
      "(Physical Attribute Prediction)このタスクには説明がありません！[410/499]\n",
      "(Pose Tracking)ポーズトラッキングは、ビデオでマルチパーソンの人間のポーズを推定し、各キーポイントにフレーム間で一意のインスタンスIDを割り当てるタスクです。[411/499]\n",
      "(Probabilistic Deep Learning)このタスクには説明がありません！[412/499]\n",
      "(Product Recommendation)このタスクには説明がありません！[413/499]\n",
      "(Rain Removal)このタスクには説明がありません！[414/499]\n",
      "(Real-time Instance Segmentation)親タスク、インスタンスセグメンテーションと同様ですが、定義された設定の下でリアルタイム機能を達成することを目的としています。[415/499]\n",
      "(Region Proposal)ナンがあります[416/499]\n",
      "(Relation Extraction)関係抽出は、文のエンティティの属性と関係を予測するタスクです。[417/499]\n",
      "(Retrieval)このタスクには説明がありません！[418/499]\n",
      "(Robust Face Recognition)堅牢な顔認識は、視点、スケール、ポーズ、照明、顔画像の表現の変動がある制約のない環境で認識を実行するタスクです。[419/499]\n",
      "(Robust classification)このタスクには説明がありません！[420/499]\n",
      "(Satellite Image Classification)衛星画像分類は、コンピューター化された研究と衛星情報のパターン認識のためにリモートセンシングで使用される最も重要な手法です。これは、使用済み分類アルゴリズムに応じてトレーニングサンプルの厳密な検証を含む画像の多様性構造に基づいています。[421/499]\n",
      "(Scene Flow Estimation)シーンフローの推定は、自律的なナビゲーションのコンテキストで、環境知覚にとって重要な3D構造と3D動的シーンの3Dモーションを取得するタスクです。[422/499]\n",
      "(Scene Graph Detection)このタスクには説明がありません！[423/499]\n",
      "(Semantic Image-Text Similarity)このタスクには説明がありません！[424/499]\n",
      "(Semantic SLAM)セマンティックレベルのシーンの理解でスラム[425/499]\n",
      "(Semantic correspondence)セマンティック対応のタスクは、同じオブジェクトカテゴリの異なるインスタンス間で信頼できる視覚的対応を確立することを目的としています。[426/499]\n",
      "(Semi Supervised Learning for Image Captioning)このタスクには説明がありません！[427/499]\n",
      "(Semi-Supervised Semantic Segmentation)少数のラベル付けされた例と多数の非標識例でトレーニングされたモデルは、画像をセグメント化することを学ぶことを目的としています（つまり、すべてのピクセルにクラスを割り当てます）。[428/499]\n",
      "(Shadow Removal)このタスクには説明がありません！[429/499]\n",
      "(Single Image Deraining)このタスクには説明がありません！[430/499]\n",
      "(Single-object discovery)このタスクには説明がありません！[431/499]\n",
      "(Sketch Recognition)このタスクには説明がありません！[432/499]\n",
      "(Small Object Detection)小さなオブジェクトの検出は、画像やビデオで小さなオブジェクトを検出およびローカライズすることを伴うコンピュータービジョンタスクです。[433/499]\n",
      "(Sparse Learning)このタスクには説明がありません！[434/499]\n",
      "(Sparse Learning and binarization)このタスクには説明がありません！[435/499]\n",
      "(Surface Reconstruction)このタスクには説明がありません！[436/499]\n",
      "(Synthetic-to-Real Translation)合成間翻訳は、合成（または仮想）データから実際のデータへのドメイン適応のタスクです。[437/499]\n",
      "(Text Retrieval)このタスクには説明がありません！[438/499]\n",
      "(Text based Person Retrieval)このタスクには説明がありません！[439/499]\n",
      "(Time Series Analysis)時系列分析では、意味のある統計やその他のデータの特性を抽出するために、時系列データを分析するための方法が含まれています。[440/499]\n",
      "(Time Series Classification)時系列分類は、多くの主題ドメインとアプリケーションで役立つ一般的なタスクです。[441/499]\n",
      "(Token Classification)このタスクには説明がありません！[442/499]\n",
      "(Traffic Sign Recognition)交通標識の認識は、画像またはビデオの交通標識を認識するタスクです。[443/499]\n",
      "(Trajectory Forecasting)軌道予測は、過去の軌跡と過去の軌跡に基づいて、シーン内のすべての移動剤（人間、車両など）の将来の軌跡を予測モデルを予測する順次予測タスクです。[444/499]\n",
      "(Unconditional Image Generation)このタスクには説明がありません！[445/499]\n",
      "(Universal Domain Adaptation)このタスクには説明がありません！[446/499]\n",
      "(Unsupervised Facial Landmark Detection)[1]によって普及した監視されていない設定での顔のランドマーク検出。[447/499]\n",
      "(Unsupervised Object Localization)このタスクには説明がありません！[448/499]\n",
      "(Unsupervised Person Re-Identification)このタスクには説明がありません！[449/499]\n",
      "(Unsupervised Pre-training)非監視されていない（自己監視）補助タスクを使用して、非標識データに関するニューラルネットワークを事前に訓練します。[450/499]\n",
      "(Unsupervised Saliency Detection)このタスクには説明がありません！[451/499]\n",
      "(Video Frame Interpolation)ナンがあります[452/499]\n",
      "(Video Generation)（さまざまなビデオ生成タスク。GIFクレジット：Magvit）[453/499]\n",
      "(Video Object Tracking)ビデオオブジェクト検出は、空間情報と時間的情報の両方を使用して、ビデオのターゲットを検出することを目的としています。[454/499]\n",
      "(Video Salient Object Detection)ビデオ顕著なオブジェクト検出（VSOD）は、一般的なフリービューリング中にHVSの背後にある基礎となるメカニズムを理解し、例えばビデオセグメンテーション、ビデオキャプション、ビデオ圧縮、自動運転、ロボット[455/499]\n",
      "(Video Summarization)ビデオの要約は、最も有益で重要な部分を選択することにより、ビデオコンテンツを要約する短い概要を生成することを目的としています。[456/499]\n",
      "(Video-Based Person Re-Identification)ビデオベースの人の再識別（Reid）は、複数のカメラのクエリ担当者と同じアイデンティティで人ビデオを取得することを目指しています[457/499]\n",
      "(Visual Grounding)Visual Grounding（VG）は、自然言語クエリに基づいて、画像内の最も関連性の高いオブジェクトまたは領域を見つけることを目的としています。[458/499]\n",
      "(Weakly Supervised Defect Detection)このタスクには説明がありません！[459/499]\n",
      "(Weakly-Supervised Semantic Segmentation)セマンティックセグメンテーションタスクは、画像内の各ピクセルにセットされたラベルからラベルを割り当てることです。[461/499]\n",
      "(Zero-Shot Cross-Modal Retrieval)ゼロショットクロスモーダル検索は、トレーニングの例を受け取ることなく、さまざまなモダリティで関連するアイテムを見つけるタスクです。[462/499]\n",
      "(regression)このタスクには説明がありません！[463/499]\n",
      "(2D Cyclist Detection)このタスクには説明がありません！[464/499]\n",
      "(2D Semantic Segmentation task 1 (8 classes))このタスクには説明がありません！[465/499]\n",
      "(2D Semantic Segmentation task 3 (25 classes))このタスクには説明がありません！[466/499]\n",
      "(3D Anomaly Detection)3Dのみの異常検出[467/499]\n",
      "(3D Classification)このタスクには説明がありません！[468/499]\n",
      "(3D Facial Landmark Localization)画像：Zhang et al[469/499]\n",
      "(3D Lane Detection)このタスクには説明がありません！[470/499]\n",
      "(3D Multi-Object Tracking)画像：Weng et al[471/499]\n",
      "(3D Multi-Person Mesh Recovery)このタスクには説明がありません！[472/499]\n",
      "(3D Multi-Person Pose Estimation (absolute))このタスクは、絶対3Dマルチパーソンポーズ推定（カメラ中心の座標）を解決することを目的としています。[473/499]\n",
      "(3D Object Detection From Stereo Images)ステレオカメラからのみ配向3D境界ボックスを推定します。[474/499]\n",
      "(3D Room Layouts From A Single RGB Panorama)画像：Zou et al[475/499]\n",
      "(3D-Aware Image Synthesis)このタスクには説明がありません！[476/499]\n",
      "(6D Pose Estimation using RGBD)画像：Zeng et al[477/499]\n",
      "(Action Classification)画像ソース：Kinetics Human Action Video Dataset[478/499]\n",
      "(Action Generation)このタスクには説明がありません！[479/499]\n",
      "(Activity Detection)拡張ビデオでのアクティビティの検出。[480/499]\n",
      "(Adversarial Attack)敵対的な攻撃は、機械学習モデルの予測を変更する摂動を見つけるためのテクニックです。[481/499]\n",
      "(Aesthetics Quality Assessment)美的関連の主観的評価の自動評価。[482/499]\n",
      "(Affordance Detection)アフォーダンス検出とは、画像内のオブジェクトの潜在的なアクションの可能性を識別することを指します。これは、ロボットの知覚と操作の重要な能力です。[483/499]\n",
      "(Autonomous Navigation)自律的なナビゲーションは、人間のガイダンスなしで、またはその周辺に車両またはロボットを自律的にナビゲートするタスクです。[484/499]\n",
      "(Bias Detection)バイアス検出は、モデルの人種差別、性差別、その他の差別的行動を検出および測定するタスクです（出典：https：[485/499]\n",
      "(Blood Cell Detection)このタスクには説明がありません！[486/499]\n",
      "(Box-supervised Instance Segmentation)このタスクは、弱く境界のあるボックスアノテーションでインスタンスセグメンテーションを実現することを目的としています。[487/499]\n",
      "(Brain Segmentation)（画像クレジット：MRIにおける皮質下セグメンテーションのための3D完全畳み込みネットワーク：大規模な研究）[488/499]\n",
      "(Breast Cancer Histology Image Classification)このタスクには説明がありません！[489/499]\n",
      "(Building change detection for remote sensing images)このタスクには説明がありません！[490/499]\n",
      "(Camera Relocalization)「カメラの再局在化、または画像ベースのローカリゼーションは、ロボット工学とコンピュータービジョンの基本的な問題です。これは、視覚シーンの表現からカメラのポーズを決定するプロセスを指し、自律車両のナビゲーション、モーションからの構造などの多くのアプリケーションに不可欠です。[491/499]\n",
      "(Camouflaged Object Segmentation)カモフラージュオブジェクトセグメンテーション（COS）またはカモフラージュオブジェクト検出（COD）。[492/499]\n",
      "(Cardiac Segmentation)このタスクには説明がありません！[493/499]\n",
      "(Cell Segmentation)セルセグメンテーションは、顕微鏡画像ドメインをセグメントに分割するタスクであり、セルの個々のインスタンスを表します。[494/499]\n",
      "(Clothes Landmark Detection)このタスクには説明がありません！[496/499]\n",
      "(Co-Salient Object Detection)協調性オブジェクトの検出は、画像グループの一般的で顕著な前景領域（またはオブジェクト）を強調することを目的とする計算上の問題です。[497/499]\n",
      "(Core set discovery)機械学習のコアセットは、監視されたアルゴリズムがセット全体の使用時に得られたものと同じくらい良い結果を提供できるようにする最小限のトレーニングサンプルとして定義されます。[498/499]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(description)):\n",
    "    try:\n",
    "        dic = {}\n",
    "        dic['idx'] = i\n",
    "        dic['タスク'] = description.task[i] + '(' + translator.translate(description.task[i])    + ')'\n",
    "        dic['概要'] = translator.translate(description.script[i])\n",
    "        dic['url'] = description.url[i]\n",
    "        print(f'({description.task[i]})' + dic['概要'] + '[' + str(i) + '/' + str(len(description)) + ']', flush=True)\n",
    "        jpscript.append(dic)\n",
    "    except:\n",
    "        error.append({'idx': i, 'task': description.task[i]})\n",
    "translator.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = './jp_image.csv'\n",
    "ename = './jp_image_error.csv'\n",
    "jp_summary = pd.DataFrame(jpscript)\n",
    "jp_summary.to_csv(name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc57351d2584f2871f94296d5548d96a7c694ce24b62e2c3a75ca1e7b2d651ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
